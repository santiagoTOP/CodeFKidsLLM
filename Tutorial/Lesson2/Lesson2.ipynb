{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lesson2 浦语言LLM Demo"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bafd265ad8f237b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 部署 InternLM2-Chat-1.8B 模型进行智能对话"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7999a40aa441dbc3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 配置环境\n",
    "- 创建虚拟环境\n",
    "- 激活环境\n",
    "- 安装必要的环境依赖包"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "579001558857f85f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# conda create -n demo python==3.10 -y\n",
    "# conda activate demo\n",
    "# conda install pytorch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 pytorch-cuda=11.7 -c pytorch -c nvidia"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7f3b2749252595b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 安装项目运行所需的依赖包"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a41b9ff17c44f4b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pip install huggingface-hub==0.17.3\n",
    "# pip install transformers==4.34 \n",
    "# pip install psutil==5.9.8\n",
    "# pip install accelerate==0.24.1\n",
    "# pip install streamlit==1.32.2 \n",
    "# pip install matplotlib==3.8.3 \n",
    "# pip install modelscope==1.9.5\n",
    "# pip install sentencepiece==0.1.99"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42ad67f0b129b4da"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 下载模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea4db48736f46ff8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "from modelscope.hub.snapshot_download import snapshot_download\n",
    "\n",
    "# 创建保存模型目录\n",
    "os.system(\"mkdir /root/models\")\n",
    "\n",
    "# save_dir是模型保存到本地的目录\n",
    "save_dir=\"/root/models\"\n",
    "\n",
    "snapshot_download(\"Shanghai_AI_Laboratory/internlm2-chat-1_8b\", cache_dir=save_dir, revision='v1.1.0')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcfaf556fdcf7a2c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 运行模型示例"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa2a00b2ac18ccd2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "model_name_or_path = \"/root/models/Shanghai_AI_Laboratory/internlm2-chat-1_8b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True, device_map='cuda:0')\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=True, torch_dtype=torch.bfloat16, device_map='cuda:0')\n",
    "model = model.eval()\n",
    "\n",
    "system_prompt = \"\"\"You are an AI assistant whose name is InternLM (书生·浦语).\n",
    "- InternLM (书生·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be helpful, honest, and harmless.\n",
    "- InternLM (书生·浦语) can understand and communicate fluently in the language chosen by the user such as English and 中文.\n",
    "\"\"\"\n",
    "\n",
    "messages = [(system_prompt, '')]\n",
    "\n",
    "print(\"=============Welcome to InternLM chatbot, type 'exit' to exit.=============\")\n",
    "\n",
    "while True:\n",
    "    input_text = input(\"\\nUser  >>> \")\n",
    "    input_text = input_text.replace(' ', '')\n",
    "    if input_text == \"exit\":\n",
    "        break\n",
    "\n",
    "    length = 0\n",
    "    for response, _ in model.stream_chat(tokenizer, input_text, messages):\n",
    "        if response is not None:\n",
    "            print(response[length:], flush=True, end=\"\")\n",
    "            length = len(response)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55dc28240082e6e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 部署第三方模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fc5600e323b7f48"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 下载模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f9033dfeb71dd45"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "#模型下载\n",
    "from modelscope.hub.snapshot_download import snapshot_download\n",
    "\n",
    "# 创建保存模型目录\n",
    "os.system(\"mkdir -p /root/models\")\n",
    "\n",
    "# save_dir是模型保存到本地的目录\n",
    "save_dir=\"/root/models\"\n",
    "\n",
    "snapshot_download('JimmyMa99/BaJie-Chat-mini', cache_dir=save_dir)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "223a82e6c80101e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 构建streamlit网页界面"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e49832a35dd821c1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# isort: skip_file\n",
    "import copy\n",
    "import warnings\n",
    "from dataclasses import asdict, dataclass\n",
    "from typing import Callable, List, Optional\n",
    "\n",
    "import streamlit as st\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers.generation.utils import (LogitsProcessorList,\n",
    "                                           StoppingCriteriaList)\n",
    "from transformers.utils import logging\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM  # isort: skip\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GenerationConfig:\n",
    "    # this config is used for chat to provide more diversity\n",
    "    max_length: int = 32768\n",
    "    top_p: float = 0.8\n",
    "    temperature: float = 0.8\n",
    "    do_sample: bool = True\n",
    "    repetition_penalty: float = 1.005\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate_interactive(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompt,\n",
    "    generation_config: Optional[GenerationConfig] = None,\n",
    "    logits_processor: Optional[LogitsProcessorList] = None,\n",
    "    stopping_criteria: Optional[StoppingCriteriaList] = None,\n",
    "    prefix_allowed_tokens_fn: Optional[Callable[[int, torch.Tensor],\n",
    "                                                List[int]]] = None,\n",
    "    additional_eos_token_id: Optional[int] = None,\n",
    "    **kwargs,\n",
    "):\n",
    "    inputs = tokenizer([prompt], padding=True, return_tensors='pt')\n",
    "    input_length = len(inputs['input_ids'][0])\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = v.cuda()\n",
    "    input_ids = inputs['input_ids']\n",
    "    _, input_ids_seq_length = input_ids.shape[0], input_ids.shape[-1]\n",
    "    if generation_config is None:\n",
    "        generation_config = model.generation_config\n",
    "    generation_config = copy.deepcopy(generation_config)\n",
    "    model_kwargs = generation_config.update(**kwargs)\n",
    "    bos_token_id, eos_token_id = (  # noqa: F841  # pylint: disable=W0612\n",
    "        generation_config.bos_token_id,\n",
    "        generation_config.eos_token_id,\n",
    "    )\n",
    "    if isinstance(eos_token_id, int):\n",
    "        eos_token_id = [eos_token_id]\n",
    "    if additional_eos_token_id is not None:\n",
    "        eos_token_id.append(additional_eos_token_id)\n",
    "    has_default_max_length = kwargs.get(\n",
    "        'max_length') is None and generation_config.max_length is not None\n",
    "    if has_default_max_length and generation_config.max_new_tokens is None:\n",
    "        warnings.warn(\n",
    "            f\"Using 'max_length''s default ({repr(generation_config.max_length)}) \\\n",
    "                to control the generation length. \"\n",
    "            'This behaviour is deprecated and will be removed from the \\\n",
    "                config in v5 of Transformers -- we'\n",
    "            ' recommend using `max_new_tokens` to control the maximum \\\n",
    "                length of the generation.',\n",
    "            UserWarning,\n",
    "        )\n",
    "    elif generation_config.max_new_tokens is not None:\n",
    "        generation_config.max_length = generation_config.max_new_tokens + \\\n",
    "            input_ids_seq_length\n",
    "        if not has_default_max_length:\n",
    "            logger.warn(  # pylint: disable=W4902\n",
    "                f\"Both 'max_new_tokens' (={generation_config.max_new_tokens}) \"\n",
    "                f\"and 'max_length'(={generation_config.max_length}) seem to \"\n",
    "                \"have been set. 'max_new_tokens' will take precedence. \"\n",
    "                'Please refer to the documentation for more information. '\n",
    "                '(https://huggingface.co/docs/transformers/main/'\n",
    "                'en/main_classes/text_generation)',\n",
    "                UserWarning,\n",
    "            )\n",
    "\n",
    "    if input_ids_seq_length >= generation_config.max_length:\n",
    "        input_ids_string = 'input_ids'\n",
    "        logger.warning(\n",
    "            f\"Input length of {input_ids_string} is {input_ids_seq_length}, \"\n",
    "            f\"but 'max_length' is set to {generation_config.max_length}. \"\n",
    "            'This can lead to unexpected behavior. You should consider'\n",
    "            \" increasing 'max_new_tokens'.\")\n",
    "\n",
    "    # 2. Set generation parameters if not already defined\n",
    "    logits_processor = logits_processor if logits_processor is not None \\\n",
    "        else LogitsProcessorList()\n",
    "    stopping_criteria = stopping_criteria if stopping_criteria is not None \\\n",
    "        else StoppingCriteriaList()\n",
    "\n",
    "    logits_processor = model._get_logits_processor(\n",
    "        generation_config=generation_config,\n",
    "        input_ids_seq_length=input_ids_seq_length,\n",
    "        encoder_input_ids=input_ids,\n",
    "        prefix_allowed_tokens_fn=prefix_allowed_tokens_fn,\n",
    "        logits_processor=logits_processor,\n",
    "    )\n",
    "\n",
    "    stopping_criteria = model._get_stopping_criteria(\n",
    "        generation_config=generation_config,\n",
    "        stopping_criteria=stopping_criteria)\n",
    "    logits_warper = model._get_logits_warper(generation_config)\n",
    "\n",
    "    unfinished_sequences = input_ids.new(input_ids.shape[0]).fill_(1)\n",
    "    scores = None\n",
    "    while True:\n",
    "        model_inputs = model.prepare_inputs_for_generation(\n",
    "            input_ids, **model_kwargs)\n",
    "        # forward pass to get next token\n",
    "        outputs = model(\n",
    "            **model_inputs,\n",
    "            return_dict=True,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=False,\n",
    "        )\n",
    "\n",
    "        next_token_logits = outputs.logits[:, -1, :]\n",
    "\n",
    "        # pre-process distribution\n",
    "        next_token_scores = logits_processor(input_ids, next_token_logits)\n",
    "        next_token_scores = logits_warper(input_ids, next_token_scores)\n",
    "\n",
    "        # sample\n",
    "        probs = nn.functional.softmax(next_token_scores, dim=-1)\n",
    "        if generation_config.do_sample:\n",
    "            next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)\n",
    "        else:\n",
    "            next_tokens = torch.argmax(probs, dim=-1)\n",
    "\n",
    "        # update generated ids, model inputs, and length for next step\n",
    "        input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)\n",
    "        model_kwargs = model._update_model_kwargs_for_generation(\n",
    "            outputs, model_kwargs, is_encoder_decoder=False)\n",
    "        unfinished_sequences = unfinished_sequences.mul(\n",
    "            (min(next_tokens != i for i in eos_token_id)).long())\n",
    "\n",
    "        output_token_ids = input_ids[0].cpu().tolist()\n",
    "        output_token_ids = output_token_ids[input_length:]\n",
    "        for each_eos_token_id in eos_token_id:\n",
    "            if output_token_ids[-1] == each_eos_token_id:\n",
    "                output_token_ids = output_token_ids[:-1]\n",
    "        response = tokenizer.decode(output_token_ids)\n",
    "\n",
    "        yield response\n",
    "        # stop when each sentence is finished\n",
    "        # or if we exceed the maximum length\n",
    "        if unfinished_sequences.max() == 0 or stopping_criteria(\n",
    "                input_ids, scores):\n",
    "            break\n",
    "\n",
    "\n",
    "def on_btn_click():\n",
    "    del st.session_state.messages\n",
    "\n",
    "\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    model = (AutoModelForCausalLM.from_pretrained('/root/models/JimmyMa99/BaJie-Chat-mini',trust_remote_code=True).to(torch.bfloat16).cuda())\n",
    "    tokenizer = AutoTokenizer.from_pretrained('/root/models/JimmyMa99/BaJie-Chat-mini', trust_remote_code=True)\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def prepare_generation_config():\n",
    "    with st.sidebar:\n",
    "        max_length = st.slider('Max Length',\n",
    "                               min_value=8,\n",
    "                               max_value=32768,\n",
    "                               value=32768)\n",
    "        top_p = st.slider('Top P', 0.0, 1.0, 0.8, step=0.01)\n",
    "        temperature = st.slider('Temperature', 0.0, 1.0, 0.7, step=0.01)\n",
    "        st.button('Clear Chat History', on_click=on_btn_click)\n",
    "\n",
    "    generation_config = GenerationConfig(max_length=max_length,\n",
    "                                         top_p=top_p,\n",
    "                                         temperature=temperature)\n",
    "\n",
    "    return generation_config\n",
    "\n",
    "\n",
    "user_prompt = '<|im_start|>user\\n{user}<|im_end|>\\n'\n",
    "robot_prompt = '<|im_start|>assistant\\n{robot}<|im_end|>\\n'\n",
    "cur_query_prompt = '<|im_start|>user\\n{user}<|im_end|>\\n\\\n",
    "    <|im_start|>assistant\\n'\n",
    "\n",
    "\n",
    "def combine_history(prompt):\n",
    "    messages = st.session_state.messages\n",
    "    meta_instruction = ('你是猪八戒，猪八戒说话幽默风趣，说话方式通常表现为直率、幽默，有时带有一点自嘲和调侃。'\n",
    "                        '你的话语中常常透露出对食物的喜爱和对安逸生活的向往，同时也显示出他机智和有时的懒惰特点。'\n",
    "                        '尽量保持回答的自然回答，当然你也可以适当穿插一些文言文，另外，书生·浦语是你的好朋友，是你的AI助手。')\n",
    "    total_prompt = f\"<s><|im_start|>system\\n{meta_instruction}<|im_end|>\\n\"\n",
    "    for message in messages:\n",
    "        cur_content = message['content']\n",
    "        if message['role'] == 'user':\n",
    "            cur_prompt = user_prompt.format(user=cur_content)\n",
    "        elif message['role'] == 'robot':\n",
    "            cur_prompt = robot_prompt.format(robot=cur_content)\n",
    "        else:\n",
    "            raise RuntimeError\n",
    "        total_prompt += cur_prompt\n",
    "    total_prompt = total_prompt + cur_query_prompt.format(user=prompt)\n",
    "    return total_prompt\n",
    "\n",
    "\n",
    "def main():\n",
    "    # torch.cuda.empty_cache()\n",
    "    print('load model begin.')\n",
    "    model, tokenizer = load_model()\n",
    "    print('load model end.')\n",
    "\n",
    "    st.title('猪猪Chat-InternLM2')\n",
    "\n",
    "    generation_config = prepare_generation_config()\n",
    "\n",
    "    # Initialize chat history\n",
    "    if 'messages' not in st.session_state:\n",
    "        st.session_state.messages = []\n",
    "\n",
    "    # Display chat messages from history on app rerun\n",
    "    for message in st.session_state.messages:\n",
    "        with st.chat_message(message['role']):\n",
    "            st.markdown(message['content'])\n",
    "\n",
    "    # Accept user input\n",
    "    if prompt := st.chat_input('What is up?'):\n",
    "        # Display user message in chat message container\n",
    "        with st.chat_message('user'):\n",
    "            st.markdown(prompt)\n",
    "        real_prompt = combine_history(prompt)\n",
    "        # Add user message to chat history\n",
    "        st.session_state.messages.append({\n",
    "            'role': 'user',\n",
    "            'content': prompt,\n",
    "        })\n",
    "\n",
    "        with st.chat_message('robot'):\n",
    "            message_placeholder = st.empty()\n",
    "            for cur_response in generate_interactive(\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer,\n",
    "                    prompt=real_prompt,\n",
    "                    additional_eos_token_id=92542,\n",
    "                    **asdict(generation_config),\n",
    "            ):\n",
    "                # Display robot response in chat message container\n",
    "                message_placeholder.markdown(cur_response + '▌')\n",
    "            message_placeholder.markdown(cur_response)\n",
    "        # Add robot response to chat history\n",
    "        st.session_state.messages.append({\n",
    "            'role': 'robot',\n",
    "            'content': cur_response,  # pylint: disable=undefined-loop-variable\n",
    "        })\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaa54b1e7228de0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 启动命令\n",
    "streamlit run /root/Tutorial/helloworld/bajie_chat.py --server.address 127.0.0.1 --server.port xxxx\n",
    "\n",
    "记得在本地PowerShell修改端口xxxx，以及填入对应的ssh密钥"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52a08c12996c8fcb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 使用Lagent运行InternLM2-Chat-7B模型为内核的智能体"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a0132b0293dcb1e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 下载模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c52e279f9d390dc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "from modelscope.hub.snapshot_download import snapshot_download\n",
    "\n",
    "# 创建保存模型目录\n",
    "os.system(\"mkdir /root/models\")\n",
    "\n",
    "# save_dir是模型保存到本地的目录\n",
    "save_dir=\"/root/models\"\n",
    "\n",
    "snapshot_download(\"Shanghai_AI_Laboratory/internlm2-chat-7b\", cache_dir=save_dir)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "305ef3466993e02a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 构建streamlit网页界"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f1f987ecdd40160"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import copy\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "from lagent.actions import ActionExecutor, ArxivSearch, IPythonInterpreter\n",
    "from lagent.agents.internlm2_agent import INTERPRETER_CN, META_CN, PLUGIN_CN, Internlm2Agent, Internlm2Protocol\n",
    "from lagent.llms import HFTransformer\n",
    "from lagent.llms.meta_template import INTERNLM2_META as META\n",
    "from lagent.schema import AgentStatusCode\n",
    "\n",
    "# from streamlit.logger import get_logger\n",
    "\n",
    "\n",
    "class SessionState:\n",
    "\n",
    "    def init_state(self):\n",
    "        \"\"\"Initialize session state variables.\"\"\"\n",
    "        st.session_state['assistant'] = []\n",
    "        st.session_state['user'] = []\n",
    "\n",
    "        action_list = [\n",
    "            ArxivSearch(),\n",
    "        ]\n",
    "        st.session_state['plugin_map'] = {\n",
    "            action.name: action\n",
    "            for action in action_list\n",
    "        }\n",
    "        st.session_state['model_map'] = {}\n",
    "        st.session_state['model_selected'] = None\n",
    "        st.session_state['plugin_actions'] = set()\n",
    "        st.session_state['history'] = []\n",
    "\n",
    "    def clear_state(self):\n",
    "        \"\"\"Clear the existing session state.\"\"\"\n",
    "        st.session_state['assistant'] = []\n",
    "        st.session_state['user'] = []\n",
    "        st.session_state['model_selected'] = None\n",
    "        st.session_state['file'] = set()\n",
    "        if 'chatbot' in st.session_state:\n",
    "            st.session_state['chatbot']._session_history = []\n",
    "\n",
    "\n",
    "class StreamlitUI:\n",
    "\n",
    "    def __init__(self, session_state: SessionState):\n",
    "        self.init_streamlit()\n",
    "        self.session_state = session_state\n",
    "\n",
    "    def init_streamlit(self):\n",
    "        \"\"\"Initialize Streamlit's UI settings.\"\"\"\n",
    "        st.set_page_config(\n",
    "            layout='wide',\n",
    "            page_title='lagent-web',\n",
    "            page_icon='./docs/imgs/lagent_icon.png')\n",
    "        st.header(':robot_face: :blue[Lagent] Web Demo ', divider='rainbow')\n",
    "        st.sidebar.title('模型控制')\n",
    "        st.session_state['file'] = set()\n",
    "        st.session_state['model_path'] = None\n",
    "\n",
    "    def setup_sidebar(self):\n",
    "        \"\"\"Setup the sidebar for model and plugin selection.\"\"\"\n",
    "        # model_name = st.sidebar.selectbox('模型选择：', options=['internlm'])\n",
    "        model_name = st.sidebar.text_input('模型名称：', value='internlm2-chat-7b')\n",
    "        meta_prompt = st.sidebar.text_area('系统提示词', value=META_CN)\n",
    "        da_prompt = st.sidebar.text_area('数据分析提示词', value=INTERPRETER_CN)\n",
    "        plugin_prompt = st.sidebar.text_area('插件提示词', value=PLUGIN_CN)\n",
    "        model_path = st.sidebar.text_input(\n",
    "            '模型路径：', value='internlm/internlm2-chat-20b')\n",
    "        if model_name != st.session_state['model_selected'] or st.session_state[\n",
    "                'model_path'] != model_path:\n",
    "            st.session_state['model_path'] = model_path\n",
    "            model = self.init_model(model_name, model_path)\n",
    "            self.session_state.clear_state()\n",
    "            st.session_state['model_selected'] = model_name\n",
    "            if 'chatbot' in st.session_state:\n",
    "                del st.session_state['chatbot']\n",
    "        else:\n",
    "            model = st.session_state['model_map'][model_name]\n",
    "\n",
    "        plugin_name = st.sidebar.multiselect(\n",
    "            '插件选择',\n",
    "            options=list(st.session_state['plugin_map'].keys()),\n",
    "            default=[],\n",
    "        )\n",
    "        da_flag = st.sidebar.checkbox(\n",
    "            '数据分析',\n",
    "            value=False,\n",
    "        )\n",
    "        plugin_action = [\n",
    "            st.session_state['plugin_map'][name] for name in plugin_name\n",
    "        ]\n",
    "\n",
    "        if 'chatbot' in st.session_state:\n",
    "            if len(plugin_action) > 0:\n",
    "                st.session_state['chatbot']._action_executor = ActionExecutor(\n",
    "                    actions=plugin_action)\n",
    "            else:\n",
    "                st.session_state['chatbot']._action_executor = None\n",
    "            if da_flag:\n",
    "                st.session_state[\n",
    "                    'chatbot']._interpreter_executor = ActionExecutor(\n",
    "                        actions=[IPythonInterpreter()])\n",
    "            else:\n",
    "                st.session_state['chatbot']._interpreter_executor = None\n",
    "            st.session_state['chatbot']._protocol._meta_template = meta_prompt\n",
    "            st.session_state['chatbot']._protocol.plugin_prompt = plugin_prompt\n",
    "            st.session_state[\n",
    "                'chatbot']._protocol.interpreter_prompt = da_prompt\n",
    "        if st.sidebar.button('清空对话', key='clear'):\n",
    "            self.session_state.clear_state()\n",
    "        uploaded_file = st.sidebar.file_uploader('上传文件')\n",
    "\n",
    "        return model_name, model, plugin_action, uploaded_file, model_path\n",
    "\n",
    "    def init_model(self, model_name, path):\n",
    "        \"\"\"Initialize the model based on the input model name.\"\"\"\n",
    "        st.session_state['model_map'][model_name] = HFTransformer(\n",
    "            path=path,\n",
    "            meta_template=META,\n",
    "            max_new_tokens=1024,\n",
    "            top_p=0.8,\n",
    "            top_k=None,\n",
    "            temperature=0.1,\n",
    "            repetition_penalty=1.0,\n",
    "            stop_words=['<|im_end|>'])\n",
    "        return st.session_state['model_map'][model_name]\n",
    "\n",
    "    def initialize_chatbot(self, model, plugin_action):\n",
    "        \"\"\"Initialize the chatbot with the given model and plugin actions.\"\"\"\n",
    "        return Internlm2Agent(\n",
    "            llm=model,\n",
    "            protocol=Internlm2Protocol(\n",
    "                tool=dict(\n",
    "                    begin='{start_token}{name}\\n',\n",
    "                    start_token='<|action_start|>',\n",
    "                    name_map=dict(\n",
    "                        plugin='<|plugin|>', interpreter='<|interpreter|>'),\n",
    "                    belong='assistant',\n",
    "                    end='<|action_end|>\\n',\n",
    "                ), ),\n",
    "            max_turn=7)\n",
    "\n",
    "    def render_user(self, prompt: str):\n",
    "        with st.chat_message('user'):\n",
    "            st.markdown(prompt)\n",
    "\n",
    "    def render_assistant(self, agent_return):\n",
    "        with st.chat_message('assistant'):\n",
    "            for action in agent_return.actions:\n",
    "                if (action) and (action.type != 'FinishAction'):\n",
    "                    self.render_action(action)\n",
    "            st.markdown(agent_return.response)\n",
    "\n",
    "    def render_plugin_args(self, action):\n",
    "        action_name = action.type\n",
    "        args = action.args\n",
    "        import json\n",
    "        parameter_dict = dict(name=action_name, parameters=args)\n",
    "        parameter_str = '```json\\n' + json.dumps(\n",
    "            parameter_dict, indent=4, ensure_ascii=False) + '\\n```'\n",
    "        st.markdown(parameter_str)\n",
    "\n",
    "    def render_interpreter_args(self, action):\n",
    "        st.info(action.type)\n",
    "        st.markdown(action.args['text'])\n",
    "\n",
    "    def render_action(self, action):\n",
    "        st.markdown(action.thought)\n",
    "        if action.type == 'IPythonInterpreter':\n",
    "            self.render_interpreter_args(action)\n",
    "        elif action.type == 'FinishAction':\n",
    "            pass\n",
    "        else:\n",
    "            self.render_plugin_args(action)\n",
    "        self.render_action_results(action)\n",
    "\n",
    "    def render_action_results(self, action):\n",
    "        \"\"\"Render the results of action, including text, images, videos, and\n",
    "        audios.\"\"\"\n",
    "        if (isinstance(action.result, dict)):\n",
    "            if 'text' in action.result:\n",
    "                st.markdown('```\\n' + action.result['text'] + '\\n```')\n",
    "            if 'image' in action.result:\n",
    "                # image_path = action.result['image']\n",
    "                for image_path in action.result['image']:\n",
    "                    image_data = open(image_path, 'rb').read()\n",
    "                    st.image(image_data, caption='Generated Image')\n",
    "            if 'video' in action.result:\n",
    "                video_data = action.result['video']\n",
    "                video_data = open(video_data, 'rb').read()\n",
    "                st.video(video_data)\n",
    "            if 'audio' in action.result:\n",
    "                audio_data = action.result['audio']\n",
    "                audio_data = open(audio_data, 'rb').read()\n",
    "                st.audio(audio_data)\n",
    "        elif isinstance(action.result, list):\n",
    "            for item in action.result:\n",
    "                if item['type'] == 'text':\n",
    "                    st.markdown('```\\n' + item['content'] + '\\n```')\n",
    "                elif item['type'] == 'image':\n",
    "                    image_data = open(item['content'], 'rb').read()\n",
    "                    st.image(image_data, caption='Generated Image')\n",
    "                elif item['type'] == 'video':\n",
    "                    video_data = open(item['content'], 'rb').read()\n",
    "                    st.video(video_data)\n",
    "                elif item['type'] == 'audio':\n",
    "                    audio_data = open(item['content'], 'rb').read()\n",
    "                    st.audio(audio_data)\n",
    "        if action.errmsg:\n",
    "            st.error(action.errmsg)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # logger = get_logger(__name__)\n",
    "    # Initialize Streamlit UI and setup sidebar\n",
    "    if 'ui' not in st.session_state:\n",
    "        session_state = SessionState()\n",
    "        session_state.init_state()\n",
    "        st.session_state['ui'] = StreamlitUI(session_state)\n",
    "\n",
    "    else:\n",
    "        st.set_page_config(\n",
    "            layout='wide',\n",
    "            page_title='lagent-web',\n",
    "            page_icon='./docs/imgs/lagent_icon.png')\n",
    "        st.header(':robot_face: :blue[Lagent] Web Demo ', divider='rainbow')\n",
    "    _, model, plugin_action, uploaded_file, _ = st.session_state[\n",
    "        'ui'].setup_sidebar()\n",
    "\n",
    "    # Initialize chatbot if it is not already initialized\n",
    "    # or if the model has changed\n",
    "    if 'chatbot' not in st.session_state or model != st.session_state[\n",
    "            'chatbot']._llm:\n",
    "        st.session_state['chatbot'] = st.session_state[\n",
    "            'ui'].initialize_chatbot(model, plugin_action)\n",
    "        st.session_state['session_history'] = []\n",
    "\n",
    "    for prompt, agent_return in zip(st.session_state['user'],\n",
    "                                    st.session_state['assistant']):\n",
    "        st.session_state['ui'].render_user(prompt)\n",
    "        st.session_state['ui'].render_assistant(agent_return)\n",
    "\n",
    "    if user_input := st.chat_input(''):\n",
    "        with st.container():\n",
    "            st.session_state['ui'].render_user(user_input)\n",
    "        st.session_state['user'].append(user_input)\n",
    "        # Add file uploader to sidebar\n",
    "        if (uploaded_file\n",
    "                and uploaded_file.name not in st.session_state['file']):\n",
    "\n",
    "            st.session_state['file'].add(uploaded_file.name)\n",
    "            file_bytes = uploaded_file.read()\n",
    "            file_type = uploaded_file.type\n",
    "            if 'image' in file_type:\n",
    "                st.image(file_bytes, caption='Uploaded Image')\n",
    "            elif 'video' in file_type:\n",
    "                st.video(file_bytes, caption='Uploaded Video')\n",
    "            elif 'audio' in file_type:\n",
    "                st.audio(file_bytes, caption='Uploaded Audio')\n",
    "            # Save the file to a temporary location and get the path\n",
    "\n",
    "            postfix = uploaded_file.name.split('.')[-1]\n",
    "            # prefix = str(uuid.uuid4())\n",
    "            prefix = hashlib.md5(file_bytes).hexdigest()\n",
    "            filename = f'{prefix}.{postfix}'\n",
    "            file_path = os.path.join(root_dir, filename)\n",
    "            with open(file_path, 'wb') as tmpfile:\n",
    "                tmpfile.write(file_bytes)\n",
    "            file_size = os.stat(file_path).st_size / 1024 / 1024\n",
    "            file_size = f'{round(file_size, 2)} MB'\n",
    "            # st.write(f'File saved at: {file_path}')\n",
    "            user_input = [\n",
    "                dict(role='user', content=user_input),\n",
    "                dict(\n",
    "                    role='user',\n",
    "                    content=json.dumps(dict(path=file_path, size=file_size)),\n",
    "                    name='file')\n",
    "            ]\n",
    "        if isinstance(user_input, str):\n",
    "            user_input = [dict(role='user', content=user_input)]\n",
    "        st.session_state['last_status'] = AgentStatusCode.SESSION_READY\n",
    "        for agent_return in st.session_state['chatbot'].stream_chat(\n",
    "                st.session_state['session_history'] + user_input):\n",
    "            if agent_return.state == AgentStatusCode.PLUGIN_RETURN:\n",
    "                with st.container():\n",
    "                    st.session_state['ui'].render_plugin_args(\n",
    "                        agent_return.actions[-1])\n",
    "                    st.session_state['ui'].render_action_results(\n",
    "                        agent_return.actions[-1])\n",
    "            elif agent_return.state == AgentStatusCode.CODE_RETURN:\n",
    "                with st.container():\n",
    "                    st.session_state['ui'].render_action_results(\n",
    "                        agent_return.actions[-1])\n",
    "            elif (agent_return.state == AgentStatusCode.STREAM_ING\n",
    "                  or agent_return.state == AgentStatusCode.CODING):\n",
    "                # st.markdown(agent_return.response)\n",
    "                # 清除占位符的当前内容，并显示新内容\n",
    "                with st.container():\n",
    "                    if agent_return.state != st.session_state['last_status']:\n",
    "                        st.session_state['temp'] = ''\n",
    "                        placeholder = st.empty()\n",
    "                        st.session_state['placeholder'] = placeholder\n",
    "                    if isinstance(agent_return.response, dict):\n",
    "                        action = f\"\\n\\n {agent_return.response['name']}: \\n\\n\"\n",
    "                        action_input = agent_return.response['parameters']\n",
    "                        if agent_return.response[\n",
    "                                'name'] == 'IPythonInterpreter':\n",
    "                            action_input = action_input['command']\n",
    "                        response = action + action_input\n",
    "                    else:\n",
    "                        response = agent_return.response\n",
    "                    st.session_state['temp'] = response\n",
    "                    st.session_state['placeholder'].markdown(\n",
    "                        st.session_state['temp'])\n",
    "            elif agent_return.state == AgentStatusCode.END:\n",
    "                st.session_state['session_history'] += (\n",
    "                    user_input + agent_return.inner_steps)\n",
    "                agent_return = copy.deepcopy(agent_return)\n",
    "                agent_return.response = st.session_state['temp']\n",
    "                st.session_state['assistant'].append(\n",
    "                    copy.deepcopy(agent_return))\n",
    "            st.session_state['last_status'] = agent_return.state\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "    root_dir = os.path.join(root_dir, 'tmp_dir')\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "159dfaf21cf53eb7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 启动命令\n",
    "\n",
    "streamlit run /root/demo/lagent/examples/internlm2_agent_web_demo_hf.py --server.address 127.0.0.1 --server.port xxxx\n",
    "\n",
    "记得在本地PowerShell修改端口xxxx，以及填入对应的ssh密钥"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "908a8d04228246fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 多模态大模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c35c90b73d1e44d9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 图文写作实战"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e356dea0a98789a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 下载模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9caefe8dba4ff15"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "from modelscope.hub.snapshot_download import snapshot_download\n",
    "\n",
    "# 创建保存模型目录\n",
    "os.system(\"mkdir /root/models\")\n",
    "\n",
    "# save_dir是模型保存到本地的目录\n",
    "save_dir=\"/root/models\"\n",
    "\n",
    "snapshot_download(\"Shanghai_AI_Laboratory/internlm-xcomposer2-7b\", cache_dir=save_dir)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cc3586419145230"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 构建gradio网页界面"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcb2d75be5807303"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import argparse\n",
    "import gradio as gr\n",
    "os.environ[\"GRADIO_TEMP_DIR\"] = os.path.join(os.getcwd(), 'tmp')\n",
    "import copy\n",
    "import time\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "import shutil\n",
    "import requests\n",
    "from PIL import Image, ImageFile\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from demo_asset.assets.css_html_js import custom_css\n",
    "from demo_asset.serve_utils import Stream, Iteratorize\n",
    "from demo_asset.conversation import CONV_VISION_INTERN2\n",
    "from demo_asset.download import download_image_thread\n",
    "from examples.utils import get_stopping_criteria, set_random_seed\n",
    "\n",
    "\n",
    "meta_instruction = \"\"\"You are an AI assistant whose name is InternLM-XComposer (浦语·灵笔).\n",
    "- InternLM-XComposer (浦语·灵笔) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be helpful, honest, and harmless.\n",
    "- InternLM-XComposer (浦语·灵笔) can understand and communicate fluently in the language chosen by the user such as English and 中文.\n",
    "\"\"\"\n",
    "chat_meta = \"\"\"You are an AI assistant whose name is InternLM-XComposer (浦语·灵笔).\n",
    "- InternLM-XComposer (浦语·灵笔) is a multi-modality conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be helpful, honest, and harmless.\n",
    "- InternLM-XComposer (浦语·灵笔) can understand and communicate fluently in the language chosen by the user such as English and 中文.\n",
    "- InternLM-XComposer (浦语·灵笔) is capable of comprehending and articulating responses effectively based on the provided image.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "max_section = 60\n",
    "chat_stream_output = True\n",
    "article_stream_output = True\n",
    "\n",
    "\n",
    "def get_urls(caption, exclude):\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    json_data = {'caption': caption, 'exclude': exclude, 'need_idxs': True}\n",
    "    response = requests.post('https://lingbi.openxlab.org.cn/image/similar',\n",
    "                             headers=headers,\n",
    "                             json=json_data)\n",
    "    urls = response.json()['data']['image_urls']\n",
    "    idx = response.json()['data']['indices']\n",
    "    return urls, idx\n",
    "\n",
    "\n",
    "class ImageGroup(object):\n",
    "    def __init__(self, cap, paths, pts=0):\n",
    "        #assert len(paths) == 1 or len(paths) == 4, f\"ImageGroup only support 1 or 4 images, not {len(paths)} images\"\n",
    "        self.cap = cap\n",
    "        self.paths = paths\n",
    "        self.pts = pts\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"cap: {self.cap}; paths:{self.paths}; pts:{self.pts}\"\n",
    "\n",
    "\n",
    "class ImageProcessor:\n",
    "    def __init__(self, image_size=224):\n",
    "        mean = (0.48145466, 0.4578275, 0.40821073)\n",
    "        std = (0.26862954, 0.26130258, 0.27577711)\n",
    "        self.normalize = transforms.Normalize(mean, std)\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size),\n",
    "                              interpolation=InterpolationMode.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            self.normalize,\n",
    "        ])\n",
    "\n",
    "    def __call__(self, item):\n",
    "        if isinstance(item, str):\n",
    "            item = Image.open(item).convert('RGB')\n",
    "        return self.transform(item)\n",
    "\n",
    "\n",
    "class Database(object):\n",
    "    def __init__(self):\n",
    "        self.title = '###'\n",
    "        self.hash_title = hashlib.sha256(self.title.encode()).hexdigest()\n",
    "\n",
    "    def addtitle(self, title, hash_folder, params):\n",
    "        self.title = title\n",
    "        self.hash_folder = hash_folder\n",
    "        time = datetime.now()\n",
    "        self.folder = os.path.join('databases', time.strftime(\"%Y%m%d\"), 'composition', self.hash_folder)\n",
    "        if os.path.exists(self.folder):\n",
    "            shutil.rmtree(self.folder)\n",
    "\n",
    "        os.makedirs(self.folder)\n",
    "        with open(os.path.join(self.folder, 'index.txt'), 'w') as fd:\n",
    "            fd.write(self.title + '\\n')\n",
    "            fd.write(self.hash_title + '\\n')\n",
    "            fd.write(str(time) + '\\n')\n",
    "            for key, val in params.items():\n",
    "                fd.write(f\"{key}:{val}\" + '\\n')\n",
    "            fd.write('\\n')\n",
    "\n",
    "    def prepare_save_article(self, text_imgs, src_folder, tgt_folder):\n",
    "        save_text = ''\n",
    "        for txt, img in text_imgs:\n",
    "            save_text += txt + '\\n'\n",
    "            if img is not None:\n",
    "                save_text += f'<div align=\"center\"> <img src={os.path.basename(img.paths[img.pts])} width = 500/> </div>'\n",
    "                path = os.path.join(src_folder, os.path.basename(img.paths[img.pts]))\n",
    "                dst_path = os.path.join(tgt_folder, os.path.basename(img.paths[img.pts]))\n",
    "                if not os.path.exists(dst_path):\n",
    "                    if os.path.exists(path):\n",
    "                        shutil.copy(path, tgt_folder)\n",
    "                    else:\n",
    "                        shutil.copy(img.paths[img.pts], tgt_folder)\n",
    "        return save_text\n",
    "\n",
    "    def addarticle(self, text_imgs):\n",
    "        if len(text_imgs) > 0:\n",
    "            images_folder = os.path.join(self.folder, 'images')\n",
    "            os.makedirs(images_folder, exist_ok=True)\n",
    "\n",
    "        save_text = self.prepare_save_article(text_imgs, os.path.join('articles', self.hash_folder), images_folder)\n",
    "\n",
    "        with open(os.path.join(self.folder, 'generate.MD'), 'w') as f:\n",
    "            f.writelines(save_text)\n",
    "\n",
    "    def addedit(self, edit_type, inst_edit, text_imgs):\n",
    "        timestamp = datetime.now()\n",
    "        with open(os.path.join(self.folder, 'index.txt'), 'a+') as f:\n",
    "            f.write(str(edit_type) + '\\n')\n",
    "            f.write(str(inst_edit) + '\\n')\n",
    "            f.write(str(timestamp) + '\\n\\n')\n",
    "\n",
    "        save_text = self.prepare_save_article(text_imgs, os.path.join('articles', self.hash_folder), os.path.join(self.folder, 'images'))\n",
    "        with open(os.path.join(self.folder, str(timestamp).replace(' ', '-') + '.MD'), 'w') as f:\n",
    "            f.writelines(save_text)\n",
    "\n",
    "\n",
    "class Demo_UI:\n",
    "    def __init__(self, code_path, num_gpus=1):\n",
    "        self.code_path = code_path\n",
    "        self.reset()\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(code_path, trust_remote_code=True)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(code_path, device_map='cuda', trust_remote_code=True).half().eval()\n",
    "        self.model.tokenizer = tokenizer\n",
    "        self.model.vit.resize_pos()\n",
    "\n",
    "        self.vis_processor = ImageProcessor()\n",
    "\n",
    "        stop_words_ids = [92397]\n",
    "        #stop_words_ids = [92542]\n",
    "        self.stopping_criteria = get_stopping_criteria(stop_words_ids)\n",
    "        set_random_seed(1234)\n",
    "        self.r2 = re.compile(r'<Seg[0-9]*>')\n",
    "        self.withmeta = False\n",
    "        self.database = Database()\n",
    "\n",
    "    def reset(self):\n",
    "        self.pt = 0\n",
    "        self.img_pt = 0\n",
    "        self.texts_imgs = []\n",
    "        self.open_edit = False\n",
    "        self.hash_folder = '12345'\n",
    "        self.instruction = ''\n",
    "\n",
    "    def reset_components(self):\n",
    "        return (gr.Markdown(visible=True, value=''),) + (gr.Markdown(visible=False, value=''),) * (max_section - 1) + (\n",
    "                gr.Button(visible=False),) * max_section + (gr.Image(visible=False),) * max_section + (gr.Accordion(visible=False),) * max_section * 2\n",
    "\n",
    "    def text2instruction(self, text):\n",
    "        if self.withmeta:\n",
    "            return f\"[UNUSED_TOKEN_146]system\\n{meta_instruction}[UNUSED_TOKEN_145]\\n[UNUSED_TOKEN_146]user\\n{text}[UNUSED_TOKEN_145]\\n[UNUSED_TOKEN_146]assistant\\n\"\n",
    "        else:\n",
    "            return f\"[UNUSED_TOKEN_146]user\\n{text}[UNUSED_TOKEN_145]\\n[UNUSED_TOKEN_146]assistant\\n\"\n",
    "\n",
    "    def get_images_xlab(self, caption, pt, exclude):\n",
    "        urls, idxs = get_urls(caption.strip()[:53], exclude)\n",
    "        print(urls[0])\n",
    "        print('download image with url')\n",
    "        download_image_thread(urls,\n",
    "                              folder='articles/' + self.hash_folder,\n",
    "                              index=pt,\n",
    "                              num_processes=4)\n",
    "        print('image downloaded')\n",
    "        return idxs\n",
    "\n",
    "    def generate(self, text, random, beam, max_length, repetition):\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                input_ids = self.model.tokenizer(text, return_tensors=\"pt\")['input_ids']\n",
    "                len_input_tokens = len(input_ids[0])\n",
    "\n",
    "                generate = self.model.generate(input_ids.cuda(),\n",
    "                                                do_sample=random,\n",
    "                                                num_beams=beam,\n",
    "                                                temperature=1.,\n",
    "                                                repetition_penalty=float(repetition),\n",
    "                                                stopping_criteria=self.stopping_criteria,\n",
    "                                                max_new_tokens=max_length,\n",
    "                                                top_p=0.8,\n",
    "                                                top_k=40,\n",
    "                                                length_penalty=1.0)\n",
    "        response = generate[0].tolist()\n",
    "        response = response[len_input_tokens:]\n",
    "        response = self.model.tokenizer.decode(response, skip_special_tokens=True)\n",
    "        response = response.replace('[UNUSED_TOKEN_145]', '')\n",
    "        response = response.replace('[UNUSED_TOKEN_146]', '')\n",
    "        return response\n",
    "\n",
    "    def generate_with_emb(self, emb, random, beam, max_length, repetition, im_mask=None):\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                generate = self.model.generate(inputs_embeds=emb,\n",
    "                                                do_sample=random,\n",
    "                                                num_beams=beam,\n",
    "                                                temperature=1.,\n",
    "                                                repetition_penalty=float(repetition),\n",
    "                                                stopping_criteria=self.stopping_criteria,\n",
    "                                                max_new_tokens=max_length,\n",
    "                                                top_p=0.8,\n",
    "                                                top_k=40,\n",
    "                                                length_penalty=1.0,\n",
    "                                                im_mask=im_mask)\n",
    "        response = generate[0].tolist()\n",
    "        response = self.model.tokenizer.decode(response, skip_special_tokens=True)\n",
    "        response = response.replace('[UNUSED_TOKEN_145]', '')\n",
    "        response = response.replace('[UNUSED_TOKEN_146]', '')\n",
    "        return response\n",
    "\n",
    "    def extract_imgfeat(self, img_paths):\n",
    "        if len(img_paths) == 0:\n",
    "            return None\n",
    "        images = []\n",
    "        for j in range(len(img_paths)):\n",
    "            image = self.vis_processor(img_paths[j])\n",
    "            images.append(image)\n",
    "        images = torch.stack(images, dim=0)\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                img_embeds = self.model.encode_img(images)\n",
    "        return img_embeds\n",
    "\n",
    "    def generate_loc(self, text_sections, upimages, image_num):\n",
    "        full_txt = ''.join(text_sections)\n",
    "        input_text = '<image> ' * len(upimages) + f'给定文章\"{full_txt}\" 根据上述文章，选择适合插入图像的{image_num}行'\n",
    "        instruction = self.text2instruction(input_text) + '适合插入图像的行是'\n",
    "        print(instruction)\n",
    "\n",
    "        if len(upimages) > 0:\n",
    "            img_embeds = self.extract_imgfeat(upimages)\n",
    "            input_embeds, im_mask, _ = self.interleav_wrap(instruction, img_embeds)\n",
    "            output_text = self.generate_with_emb(input_embeds, True, 1, 200, 1.005, im_mask=im_mask)\n",
    "        else:\n",
    "            output_text = self.generate(instruction, True, 1, 200, 1.005)\n",
    "\n",
    "        inject_text = '适合插入图像的行是' + output_text\n",
    "        print(inject_text)\n",
    "\n",
    "        locs = [int(m[4:-1]) for m in self.r2.findall(inject_text)]\n",
    "        print(locs)\n",
    "        return inject_text, locs\n",
    "\n",
    "    def generate_cap(self, text_sections, pos, progress):\n",
    "        pasts = ''\n",
    "        caps = {}\n",
    "        for idx, po in progress.tqdm(enumerate(pos), desc=\"image captioning\"):\n",
    "            full_txt = ''.join(text_sections[:po + 2])\n",
    "            if idx > 0:\n",
    "                past = pasts[:-2] + '。'\n",
    "            else:\n",
    "                past = pasts\n",
    "\n",
    "            #input_text = f' <|User|>: 给定文章\"{full_txt}\" {past}给出适合在<Seg{po}>后插入的图像对应的标题。' + ' \\n<TOKENS_UNUSED_0> <|Bot|>: 标题是\"'\n",
    "            input_text = f'给定文章\"{full_txt}\" {past}给出适合在<Seg{po}>后插入的图像对应的标题。'\n",
    "            instruction = self.text2instruction(input_text) + '标题是\"'\n",
    "            print(instruction)\n",
    "            cap_text = self.generate(instruction, True, 1, 200, 1.005)\n",
    "            cap_text = cap_text.split('\"')[0].strip()\n",
    "            print(cap_text)\n",
    "            caps[po] = cap_text\n",
    "\n",
    "            if idx == 0:\n",
    "                pasts = f'现在<Seg{po}>后插入图像对应的标题是\"{cap_text}\"， '\n",
    "            else:\n",
    "                pasts += f'<Seg{po}>后插入图像对应的标题是\"{cap_text}\"， '\n",
    "\n",
    "        print(caps)\n",
    "        return caps\n",
    "\n",
    "    def interleav_wrap(self, text, image, max_length=4096):\n",
    "        device = image.device\n",
    "        im_len = image.shape[1]\n",
    "        image_nums = len(image)\n",
    "        parts = text.split('<image>')\n",
    "        wrap_embeds, wrap_im_mask = [], []\n",
    "        temp_len = 0\n",
    "        need_bos = True\n",
    "\n",
    "        for idx, part in enumerate(parts):\n",
    "            if len(part) > 0:\n",
    "                part_tokens = self.model.tokenizer(part,\n",
    "                                                    return_tensors='pt',\n",
    "                                                    padding='longest',\n",
    "                                                    add_special_tokens=need_bos).to(device)\n",
    "                if need_bos:\n",
    "                    need_bos = False\n",
    "                part_embeds = self.model.model.tok_embeddings(part_tokens.input_ids)\n",
    "                wrap_embeds.append(part_embeds)\n",
    "                wrap_im_mask.append(torch.zeros(part_embeds.shape[:2]))\n",
    "                temp_len += part_embeds.shape[1]\n",
    "            if idx < image_nums:\n",
    "                wrap_embeds.append(image[idx].unsqueeze(0))\n",
    "                wrap_im_mask.append(torch.ones(1, image[idx].shape[0]))\n",
    "                temp_len += im_len\n",
    "\n",
    "            if temp_len > max_length:\n",
    "                break\n",
    "\n",
    "        wrap_embeds = torch.cat(wrap_embeds, dim=1)\n",
    "        wrap_im_mask = torch.cat(wrap_im_mask, dim=1)\n",
    "        wrap_embeds = wrap_embeds[:, :max_length].to(device)\n",
    "        wrap_im_mask = wrap_im_mask[:, :max_length].to(device).bool()\n",
    "        return wrap_embeds, wrap_im_mask, temp_len\n",
    "\n",
    "    def model_select_image(self, output_text, locs, images_paths, progress):\n",
    "        print('model_select_image')\n",
    "        pre_text = ''\n",
    "        pre_img = []\n",
    "        pre_text_list = []\n",
    "        ans2idx = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "        selected = {k: 0 for k in locs}\n",
    "        for i, text in enumerate(output_text):\n",
    "            pre_text += text + '\\n'\n",
    "            if i in locs:\n",
    "                images = copy.deepcopy(pre_img)\n",
    "                for j in range(len(images_paths[i])):\n",
    "                    image = self.vis_processor(images_paths[i][j])\n",
    "                    images.append(image)\n",
    "                images = torch.stack(images, dim=0)\n",
    "\n",
    "                pre_text_list.append(pre_text)\n",
    "                pre_text = ''\n",
    "\n",
    "                images = images.cuda()\n",
    "                text = '根据给定上下文和候选图像，选择合适的配图：' + '<image>'.join(pre_text_list) + '候选图像包括: ' + '\\n'.join([chr(ord('A') + j) + '.<image>' for j in range(len(images_paths[i]))])\n",
    "                input_text = self.text2instruction(text) + '最合适的图是'\n",
    "                print(input_text)\n",
    "                with torch.no_grad():\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        img_embeds = self.model.encode_img(images)\n",
    "                        input_embeds, im_mask, len_input_tokens = self.interleav_wrap(input_text, img_embeds)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model.generate(\n",
    "                                            inputs_embeds=input_embeds,\n",
    "                                            do_sample=True,\n",
    "                                            temperature=1.,\n",
    "                                            max_new_tokens=10,\n",
    "                                            repetition_penalty=1.005,\n",
    "                                            top_p=0.8,\n",
    "                                            top_k=40,\n",
    "                                            length_penalty=1.0,\n",
    "                                            im_mask=im_mask\n",
    "                                            )\n",
    "                response = outputs[0][2:].tolist()   #<s>: C\n",
    "                #print(response)\n",
    "                out_text = self.model.tokenizer.decode(response, add_special_tokens=True)\n",
    "                print(out_text)\n",
    "\n",
    "                try:\n",
    "                    answer = out_text.lstrip()[0]\n",
    "                    pre_img.append(images[len(pre_img) + ans2idx[answer]].cpu())\n",
    "                except:\n",
    "                    print('Select fail, use first image')\n",
    "                    answer = 'A'\n",
    "                    pre_img.append(images[len(pre_img) + ans2idx[answer]].cpu())\n",
    "                selected[i] = ans2idx[answer]\n",
    "        return selected\n",
    "\n",
    "    def model_select_imagebase(self, output_text, locs, imagebase, progress):\n",
    "        print('model_select_imagebase')\n",
    "        pre_text = ''\n",
    "        pre_img = []\n",
    "        pre_text_list = []\n",
    "        selected = []\n",
    "\n",
    "        images = []\n",
    "        for j in range(len(imagebase)):\n",
    "            image = self.vis_processor(imagebase[j])\n",
    "            images.append(image)\n",
    "        images = torch.stack(images, dim=0).cuda()\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                img_embeds = self.model.encode_img(images)\n",
    "\n",
    "        for i, text in enumerate(output_text):\n",
    "            pre_text += text + '\\n'\n",
    "            if i in locs:\n",
    "                pre_text_list.append(pre_text)\n",
    "                pre_text = ''\n",
    "                print(img_embeds.shape)\n",
    "                cand_embeds = torch.stack([item for j, item in enumerate(img_embeds) if j not in selected], dim=0)\n",
    "                ans2idx = {}\n",
    "                count = 0\n",
    "                for j in range(len(img_embeds)):\n",
    "                    if j not in selected:\n",
    "                        ans2idx[chr(ord('A') + count)] = j\n",
    "                        count += 1\n",
    "\n",
    "                if cand_embeds.shape[0] > 1:\n",
    "                    text = '根据给定上下文和候选图像，选择合适的配图：' + '<image>'.join(pre_text_list) + '候选图像包括: ' + '\\n'.join([chr(ord('A') + j) + '.<image>' for j in range(len(cand_embeds))])\n",
    "                    input_text = self.text2instruction(text) + '最合适的图是'\n",
    "                    print(input_text)\n",
    "\n",
    "                    all_img = cand_embeds if len(pre_img) == 0 else torch.cat(pre_img + [cand_embeds], dim=0)\n",
    "                    input_embeds, im_mask, len_input_tokens = self.interleav_wrap(input_text, all_img)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        outputs = self.model.generate(\n",
    "                                                inputs_embeds=input_embeds,\n",
    "                                                do_sample=True,\n",
    "                                                temperature=1.,\n",
    "                                                max_new_tokens=10,\n",
    "                                                repetition_penalty=1.005,\n",
    "                                                top_p=0.8,\n",
    "                                                top_k=40,\n",
    "                                                length_penalty=1.0,\n",
    "                                                im_mask=im_mask\n",
    "                                                )\n",
    "                    response = outputs[0][2:].tolist()   #<s>: C\n",
    "                    #print(response)\n",
    "                    out_text = self.model.tokenizer.decode(response, add_special_tokens=True)\n",
    "                    print(out_text)\n",
    "\n",
    "                    try:\n",
    "                        answer = out_text.lstrip()[0]\n",
    "                    except:\n",
    "                        print('Select fail, use first image')\n",
    "                        answer = 'A'\n",
    "                else:\n",
    "                    answer = 'A'\n",
    "\n",
    "                pre_img.append(img_embeds[ans2idx[answer]].unsqueeze(0))\n",
    "                selected.append(ans2idx[answer])\n",
    "        selected = {loc: j for loc, j in zip(locs, selected)}\n",
    "        print(selected)\n",
    "        return selected\n",
    "\n",
    "    def show_article(self, show_cap=False):\n",
    "        md_shows = []\n",
    "        imgs_show = []\n",
    "        edit_bts = []\n",
    "        for i in range(len(self.texts_imgs)):\n",
    "            text, img = self.texts_imgs[i]\n",
    "            md_shows.append(gr.Markdown(visible=True, value=text))\n",
    "            edit_bts.append(gr.Button(visible=True, interactive=True, ))\n",
    "            imgs_show.append(gr.Image(visible=False) if img is None else gr.Image(visible=True, value=img.paths[img.pts]))\n",
    "\n",
    "        print(f'show {len(md_shows)} text sections')\n",
    "        for _ in range(max_section - len(self.texts_imgs)):\n",
    "            md_shows.append(gr.Markdown(visible=False, value=''))\n",
    "            edit_bts.append(gr.Button(visible=False))\n",
    "            imgs_show.append(gr.Image(visible=False))\n",
    "\n",
    "        return md_shows + edit_bts + imgs_show\n",
    "\n",
    "    def generate_article(self, instruction, upimages, beam, repetition, max_length, random, seed):\n",
    "        self.reset()\n",
    "        set_random_seed(int(seed))\n",
    "        self.hash_folder = hashlib.sha256(instruction.encode()).hexdigest()\n",
    "        self.instruction = instruction\n",
    "        if upimages is None:\n",
    "            upimages = []\n",
    "        else:\n",
    "            upimages = [t.image.path for t in upimages.root]\n",
    "        img_instruction = '<image> ' * len(upimages)\n",
    "        instruction = img_instruction.strip() + instruction\n",
    "        text = self.text2instruction(instruction)\n",
    "        print('random generate:{}'.format(random))\n",
    "        if article_stream_output:\n",
    "            if len(upimages) == 0:\n",
    "                input_ids = self.model.tokenizer(text, return_tensors=\"pt\")['input_ids']\n",
    "                input_embeds = self.model.model.tok_embeddings(input_ids.cuda())\n",
    "                im_mask = None\n",
    "            else:\n",
    "                images = []\n",
    "                for j in range(len(upimages)):\n",
    "                    image = self.vis_processor(upimages[j])\n",
    "                    images.append(image)\n",
    "                images = torch.stack(images, dim=0)\n",
    "                with torch.no_grad():\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        img_embeds = self.model.encode_img(images)\n",
    "\n",
    "                text = self.text2instruction(instruction)\n",
    "\n",
    "                input_embeds, im_mask, len_input_tokens = self.interleav_wrap(text, img_embeds)\n",
    "\n",
    "            print(text)\n",
    "            generate_params = dict(\n",
    "                inputs_embeds=input_embeds,\n",
    "                do_sample=random,\n",
    "                stopping_criteria=self.stopping_criteria,\n",
    "                repetition_penalty=float(repetition),\n",
    "                max_new_tokens=max_length,\n",
    "                top_p=0.8,\n",
    "                top_k=40,\n",
    "                length_penalty=1.0,\n",
    "                im_mask=im_mask,\n",
    "            )\n",
    "            output_text = \"▌\"\n",
    "            with self.generate_with_streaming(**generate_params) as generator:\n",
    "                for output in generator:\n",
    "                    decoded_output = self.model.tokenizer.decode(output[1:])\n",
    "                    if output[-1] in [self.model.tokenizer.eos_token_id, 92542]:\n",
    "                        break\n",
    "                    output_text = decoded_output.replace('\\n', '\\n\\n') + \"▌\"\n",
    "                    yield (output_text,) + (gr.Markdown(visible=False),) * (max_section - 1) + (\n",
    "                            gr.Button(visible=False),) * max_section + (gr.Image(visible=False),) * max_section\n",
    "                    time.sleep(0.01)\n",
    "            output_text = output_text[:-1]\n",
    "            yield (output_text,) + (gr.Markdown(visible=False),) * (max_section - 1) + (\n",
    "                            gr.Button(visible=False),) * max_section + (gr.Image(visible=False),) * max_section\n",
    "        else:\n",
    "            output_text = self.generate(text, random, beam, max_length, repetition)\n",
    "\n",
    "        output_text = re.sub(r'(\\n\\s*)+', '\\n', output_text.strip())\n",
    "        print(output_text)\n",
    "\n",
    "        output_text = output_text.split('\\n')[:max_section]\n",
    "\n",
    "        self.texts_imgs = [[t, None] for t in output_text]\n",
    "        self.database.addtitle(text, self.hash_folder, params={'beam':beam, 'repetition':repetition, 'max_length':max_length, 'random':random, 'seed':seed})\n",
    "\n",
    "        if article_stream_output:\n",
    "            yield self.show_article()\n",
    "        else:\n",
    "            return self.show_article()\n",
    "\n",
    "    def insert_images(self, upimages, llmO, img_num, seed, progress=gr.Progress()):\n",
    "        set_random_seed(int(seed))\n",
    "        if not llmO:\n",
    "            output_text = [t[0] for t in self.texts_imgs]\n",
    "            idx_text_sections = [f'<Seg{i}>' + ' ' + it + '\\n' for i, it in enumerate(output_text)]\n",
    "\n",
    "            if img_num == 'Automatic (自动)':\n",
    "                img_num = ''\n",
    "\n",
    "            if upimages is None:\n",
    "                upimages = []\n",
    "            else:\n",
    "                upimages = [t.image.path for t in upimages.root]\n",
    "\n",
    "            inject_text, locs = self.generate_loc(idx_text_sections, upimages, img_num)\n",
    "            if len(upimages) == 0:\n",
    "                caps = self.generate_cap(idx_text_sections, locs, progress)\n",
    "\n",
    "                self.ex_idxs = []\n",
    "                images_paths = {}\n",
    "                for loc, cap in progress.tqdm(caps.items(), desc=\"download image\"):\n",
    "                    idxs = self.get_images_xlab(cap, self.img_pt, self.ex_idxs)\n",
    "                    paths = [os.path.join('articles', self.hash_folder, f'temp_{self.img_pt}_{i}.png') for i in range(4)]\n",
    "                    images_paths[loc] = [it for it in paths if os.path.exists(it)]\n",
    "                    if len(images_paths[loc]) == 0:\n",
    "                        gr.Warning('Image download fail !!!')\n",
    "                        del images_paths[loc]\n",
    "                    self.img_pt += 1\n",
    "                    self.ex_idxs.extend(idxs)\n",
    "\n",
    "                locs = [k for k in caps.keys() if k in images_paths]\n",
    "\n",
    "                if True:\n",
    "                    selected = self.model_select_image(output_text, locs, images_paths, progress)\n",
    "                else:\n",
    "                    selected = {k: 0 for k in locs}\n",
    "\n",
    "                self.texts_imgs = [\n",
    "                    [t, ImageGroup(caps[i], images_paths[i], selected[i])] if i in selected else [t, None]\n",
    "                    for i, t in enumerate(output_text)]\n",
    "            else:\n",
    "                selected = self.model_select_imagebase(output_text, locs, upimages, progress)\n",
    "                self.texts_imgs = [[t, ImageGroup('', [upimages[selected[i]]])] if i in selected else [t, None] for i, t in enumerate(output_text)]\n",
    "\n",
    "        self.database.addarticle(self.texts_imgs)\n",
    "        return self.show_article()\n",
    "\n",
    "    def show_edit(self, text, pt):\n",
    "        if self.open_edit and pt != self.pt:\n",
    "            gr.Warning('Please close the editing panel before open another editing panel !!!')\n",
    "            return gr.Accordion(visible=False), text, ''\n",
    "        else:\n",
    "            self.pt = pt\n",
    "            self.open_edit = True\n",
    "            return gr.Accordion(visible=True), text, ''\n",
    "\n",
    "    def show_gallery(self, img_pt):\n",
    "        if self.open_edit and img_pt != self.pt:\n",
    "            gr.Warning('Please close the editing panel before open another editing panel !!!')\n",
    "            return gr.Accordion(visible=False), '', gr.Gallery()\n",
    "        elif len(self.texts_imgs[img_pt][1].paths) == 1:\n",
    "            gr.Warning('This imag can not be edited !!!')\n",
    "            return gr.Accordion(visible=False), '', gr.Gallery()\n",
    "        else:\n",
    "            self.pt = img_pt\n",
    "            self.open_edit = True\n",
    "            gallery = gr.Gallery(value=self.texts_imgs[img_pt][1].paths)\n",
    "            return gr.Accordion(visible=True), self.texts_imgs[img_pt][1].cap, gallery\n",
    "\n",
    "    def hide_edit(self, flag=False):\n",
    "        self.open_edit = flag\n",
    "        return gr.Accordion(visible=False), None, gr.Textbox(value='', interactive=False), ''\n",
    "\n",
    "    def hide_gallery(self):\n",
    "        self.open_edit = False\n",
    "        self.database.addedit('changeimage', '', self.texts_imgs)\n",
    "        return gr.Accordion(visible=False), '', gr.Gallery(value=None)\n",
    "\n",
    "    def delete_gallery(self, pt):\n",
    "        self.texts_imgs[pt][1] = None\n",
    "        return [gr.Image(visible=False, value=None)] + list(self.hide_gallery())\n",
    "\n",
    "    def edit_types_change(self, edit_type):\n",
    "        if edit_type in ['缩写', 'abbreviate']:\n",
    "            return gr.Textbox(interactive=False)\n",
    "        elif edit_type in ['扩写', '改写', '前插入一段', '后插入一段', 'expand', 'rewrite', 'insert a paragraph before', 'insert a paragraph after']:\n",
    "            return gr.Textbox(interactive=True)\n",
    "\n",
    "    def insert_image(self):\n",
    "        return list(self.hide_edit(flag=True)) + [gr.Accordion(visible=True), '', gr.Gallery(visible=True, value=None)]\n",
    "\n",
    "    def done_edit(self, edit_type, inst_edit, new_text):\n",
    "        if new_text == '':\n",
    "            self.texts_imgs = self.texts_imgs[:self.pt] + self.texts_imgs[self.pt+1:]\n",
    "        else:\n",
    "            sub_text = re.sub(r'\\n+', ' ', new_text)\n",
    "            if edit_type in ['扩写', '缩写', '改写', 'expand', 'rewrite', 'abbreviate']:\n",
    "                self.texts_imgs[self.pt][0] = sub_text\n",
    "            elif edit_type in ['前插入一段', 'insert a paragraph before']:\n",
    "                self.texts_imgs = self.texts_imgs[:self.pt] + [[sub_text, None]] + self.texts_imgs[self.pt:]\n",
    "            elif edit_type in ['后插入一段', 'insert a paragraph after']:\n",
    "                self.texts_imgs = self.texts_imgs[:self.pt+1] + [[sub_text, None]] + self.texts_imgs[self.pt+1:]\n",
    "            else:\n",
    "                print(new_text)\n",
    "                assert 0 == 1\n",
    "\n",
    "        self.database.addedit(edit_type, inst_edit, self.texts_imgs)\n",
    "        return list(self.hide_edit()) + list(self.show_article())\n",
    "\n",
    "    def paragraph_edit(self, edit_type, text, instruction, pts):\n",
    "        if edit_type in ['扩写', 'expand']:\n",
    "            inst_text = f'扩写以下段落：{text}\\n基于以下素材：{instruction}'\n",
    "        elif edit_type in ['改写', 'rewrite']:\n",
    "            inst_text = f'改写以下段落：{text}\\n基于以下素材：{instruction}'\n",
    "        elif edit_type in ['缩写', 'abbreviate']:\n",
    "            inst_text = '缩写以下段落：' + text\n",
    "        elif edit_type in ['前插入一段', 'insert a paragraph before']:\n",
    "            pre_text = '' if pts == 0 else self.texts_imgs[pts-1][0]\n",
    "            inst_text = f'在以下两段中插入一段。\\n第一段：{pre_text}\\n第二段：{text}\\n插入段的大纲：{instruction}'\n",
    "        elif edit_type in ['后插入一段', 'insert a paragraph after']:\n",
    "            post_text = '' if pts + 1 >= len(self.texts_imgs) else self.texts_imgs[pts + 1][0]\n",
    "            inst_text = f'在以下两段中插入一段。\\n第一段：{text}\\n第二段：{post_text}\\n插入段的大纲：{instruction}'\n",
    "        elif edit_type is None:\n",
    "            if article_stream_output:\n",
    "                yield text, gr.Button(interactive=True), gr.Button(interactive=True)\n",
    "            else:\n",
    "                return text, gr.Button(interactive=True), gr.Button(interactive=True)\n",
    "\n",
    "        if instruction == '' and edit_type in ['前插入一段', '后插入一段', 'insert a paragraph before', 'insert a paragraph after']:\n",
    "            gr.Warning('Please input the instruction !!!')\n",
    "            if article_stream_output:\n",
    "                yield '', gr.Button(interactive=True), gr.Button(interactive=True)\n",
    "            else:\n",
    "                return '', gr.Button(interactive=True), gr.Button(interactive=True)\n",
    "        else:\n",
    "            print(inst_text)\n",
    "            instruction = self.text2instruction(inst_text)\n",
    "            if article_stream_output:\n",
    "                input_ids = self.model.tokenizer(instruction, return_tensors=\"pt\")['input_ids']\n",
    "                len_input_tokens = len(input_ids[0])\n",
    "                input_embeds = self.model.model.tok_embeddings(input_ids.cuda())\n",
    "                generate_params = dict(\n",
    "                    inputs_embeds=input_embeds,\n",
    "                    do_sample=True,\n",
    "                    stopping_criteria=self.stopping_criteria,\n",
    "                    repetition_penalty=1.005,\n",
    "                    max_length=500 - len_input_tokens,\n",
    "                    top_p=0.8,\n",
    "                    top_k=40,\n",
    "                    length_penalty=1.0\n",
    "                )\n",
    "                output_text = \"▌\"\n",
    "                with self.generate_with_streaming(**generate_params) as generator:\n",
    "                    for output in generator:\n",
    "                        decoded_output = self.model.tokenizer.decode(output[1:])\n",
    "                        if output[-1] in [self.model.tokenizer.eos_token_id, 92542]:\n",
    "                            break\n",
    "                        output_text = decoded_output.replace('\\n', '\\n\\n') + \"▌\"\n",
    "                        yield output_text, gr.Button(interactive=False), gr.Button(interactive=False)\n",
    "                        time.sleep(0.1)\n",
    "                output_text = output_text[:-1]\n",
    "                print(output_text)\n",
    "                yield output_text, gr.Button(interactive=True), gr.Button(interactive=True)\n",
    "            else:\n",
    "                output_text = self.generate(text, True, 1, 500, 1.005)\n",
    "                return output_text, gr.Button(interactive=True), gr.Button(interactive=True)\n",
    "\n",
    "    def search_image(self, text, pt):\n",
    "        if text == '':\n",
    "            return gr.Gallery()\n",
    "\n",
    "        idxs = self.get_images_xlab(text, self.img_pt, self.ex_idxs)\n",
    "        images_paths = [os.path.join('articles', self.hash_folder, f'temp_{self.img_pt}_{i}.png') for i in\n",
    "                             range(4)]\n",
    "        self.img_pt += 1\n",
    "        self.ex_idxs.extend(idxs)\n",
    "\n",
    "        self.texts_imgs[pt][1] = ImageGroup(text, images_paths)\n",
    "\n",
    "        ga_show = gr.Gallery(visible=True, value=images_paths)\n",
    "        return ga_show, gr.Image(visible=True, value=images_paths[0])\n",
    "\n",
    "    def replace_image(self, pt, evt: gr.SelectData):\n",
    "        self.texts_imgs[pt][1].pts = evt.index\n",
    "        img = self.texts_imgs[pt][1]\n",
    "        return gr.Image(visible=True, value=img.paths[img.pts])\n",
    "\n",
    "    def save(self, beam, repetition, text_num, random, seed):\n",
    "        folder = 'save_articles/' + self.hash_folder\n",
    "        if os.path.exists(folder):\n",
    "            for item in os.listdir(folder):\n",
    "                os.remove(os.path.join(folder, item))\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "        save_text = '\\n'.join([self.instruction, str(beam), str(repetition), str(text_num), str(random), str(seed)]) + '\\n\\n'\n",
    "        if len(self.texts_imgs) > 0:\n",
    "            for txt, img in self.texts_imgs:\n",
    "                save_text += txt + '\\n'\n",
    "                if img is not None:\n",
    "                    save_text += f'<div align=\"center\"> <img src={os.path.basename(img.paths[img.pts])} width = 500/> </div>'\n",
    "                    path = os.path.join('articles', self.hash_folder, os.path.basename(img.paths[img.pts]))\n",
    "                    if os.path.exists(path):\n",
    "                        shutil.copy(path, folder)\n",
    "                    else:\n",
    "                        shutil.copy(img.paths[img.pts], folder)\n",
    "\n",
    "        with open(os.path.join(folder, 'io.MD'), 'w') as f:\n",
    "            f.writelines(save_text)\n",
    "\n",
    "        archived = shutil.make_archive(folder, 'zip', folder)\n",
    "        return archived\n",
    "\n",
    "    def generate_with_callback(self, callback=None, **kwargs):\n",
    "        kwargs.setdefault(\"stopping_criteria\",\n",
    "                          transformers.StoppingCriteriaList())\n",
    "        kwargs[\"stopping_criteria\"].append(Stream(callback_func=callback))\n",
    "        with torch.no_grad():\n",
    "            self.model.generate(**kwargs)\n",
    "\n",
    "    def generate_with_streaming(self, **kwargs):\n",
    "        return Iteratorize(self.generate_with_callback, kwargs, callback=None)\n",
    "\n",
    "    def change_meta(self, withmeta):\n",
    "        self.withmeta = withmeta\n",
    "\n",
    "    def upload_images(self, files):\n",
    "        if len(files) > 10:\n",
    "            gr.Warning('No more than 10 images !!!')\n",
    "            files = files[:10]\n",
    "        return gr.Gallery(value=files), gr.Dropdown(value=str(len(files)))\n",
    "\n",
    "    def clear_images(self):\n",
    "        return gr.Gallery(value=None)\n",
    "\n",
    "    def limit_imagenum(self, img_num, upshows):\n",
    "        if upshows is None:\n",
    "            return gr.Dropdown()\n",
    "        maxnum = len(upshows.root)\n",
    "        if img_num == 'Automatic (自动)' or int(img_num) > maxnum:\n",
    "            img_num = str(maxnum)\n",
    "        return gr.Dropdown(value=img_num)\n",
    "\n",
    "    def enable_like(self):\n",
    "        return [gr.Button(visible=True)] * 2\n",
    "\n",
    "    def like(self):\n",
    "        with open(os.path.join(self.database.folder, 'like.txt'), 'w') as fd:\n",
    "            fd.write('like')\n",
    "        return [gr.Button(visible=False)] * 2\n",
    "\n",
    "    def dislike(self):\n",
    "        with open(os.path.join(self.database.folder, 'like.txt'), 'w') as fd:\n",
    "            fd.write('dislike')\n",
    "        return [gr.Button(visible=False)] * 2\n",
    "\n",
    "\n",
    "def change_language(lang):\n",
    "    edit_types, inst_edits, insertIMGs, edit_dones, edit_cancels = [], [], [], [], []\n",
    "    cap_searchs, gallery_dels, gallery_dones = [], [], []\n",
    "    if lang == '中文':\n",
    "        lang_btn = gr.Button(value='English')\n",
    "        for _ in range(max_section):\n",
    "            edit_types.append(gr.Radio([\"改写\", \"扩写\", \"缩写\", \"前插入一段\", \"后插入一段\"]))\n",
    "            inst_edits.append(gr.Textbox(label='插入段落时，请输入插入段的大纲：'))\n",
    "            insertIMGs.append(gr.Button(value='在下方插入图片'))\n",
    "            edit_dones.append(gr.Button(value='确定'))\n",
    "            edit_cancels.append(gr.Button(value='取消'))\n",
    "            cap_searchs.append(gr.Button(value='搜图'))\n",
    "            gallery_dels.append(gr.Button(value='删除'))\n",
    "            gallery_dones.append(gr.Button(value='确定'))\n",
    "    elif lang == 'English':\n",
    "        lang_btn = gr.Button(value='中文')\n",
    "        for _ in range(max_section):\n",
    "            edit_types.append(gr.Radio([\"rewrite\", \"expand\", \"abbreviate\", \"insert a paragraph before\", \"insert a paragraph after\"]))\n",
    "            inst_edits.append(gr.Textbox(label='Instrcution for editing:'))\n",
    "            insertIMGs.append(gr.Button(value='Insert image below'))\n",
    "            edit_dones.append(gr.Button(value='Done'))\n",
    "            edit_cancels.append(gr.Button(value='Cancel'))\n",
    "            cap_searchs.append(gr.Button(value='Search'))\n",
    "            gallery_dels.append(gr.Button(value='Delete'))\n",
    "            gallery_dones.append(gr.Button(value='Done'))\n",
    "\n",
    "    return [lang_btn] + edit_types + inst_edits + insertIMGs + edit_dones + edit_cancels + cap_searchs + gallery_dels + gallery_dones\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--code_path\", default='internlm/internlm-xcomposer2-7b')\n",
    "parser.add_argument(\"--private\", default=False, action='store_true')\n",
    "parser.add_argument(\"--num_gpus\", default=1, type=int)\n",
    "parser.add_argument(\"--port\", default=11111, type=int)\n",
    "args = parser.parse_args()\n",
    "demo_ui = Demo_UI(args.code_path, args.num_gpus)\n",
    "\n",
    "\n",
    "with gr.Blocks(css=custom_css, title='浦语·灵笔 (InternLM-XComposer)') as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=20):\n",
    "            # gr.HTML(\"\"\"<h1 align=\"center\" id=\"space-title\" style=\"font-size:35px;\">🤗 浦语·灵笔 (InternLM-XComposer)</h1>\"\"\")\n",
    "            gr.HTML(\n",
    "                \"\"\"<h1 align=\"center\"><img src=\"https://raw.githubusercontent.com/InternLM/InternLM-XComposer/InternLM-XComposer2/assets/logo_en.png\", alt=\"InternLM-XComposer\" border=\"0\" style=\"margin: 0 auto; height: 120px;\" /></a> </h1>\"\"\"\n",
    "            )\n",
    "        with gr.Column(scale=1, min_width=100):\n",
    "            lang_btn = gr.Button(\"中文\")\n",
    "\n",
    "    with gr.Tabs(elem_classes=\"tab-buttons\") as tabs:\n",
    "        with gr.TabItem(\"📝 Write Interleaved-text-image Article (创作图文并茂文章)\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=2):\n",
    "                    instruction = gr.Textbox(label='Write an illustrated article based on the given instruction: (根据素材或指令创作图文并茂的文章)',\n",
    "                                             lines=5,\n",
    "                                             value='''根据以下标题：“中国水墨画：流动的诗意与东方美学”，创作长文章，字数不少于800字。请结合以下文本素材：\n",
    "“水墨画是由水和墨调配成不同深浅的墨色所画出的画，是绘画的一种形式，更多时候，水墨画被视为中国传统绘画，也就是国画的代表。也称国画，中国画。墨水画是中国传统画之一。墨水是国画的起源，以笔墨运用的技法基础画成墨水画。线条中锋笔，侧锋笔，顺锋和逆锋，点染，擦，破墨，拨墨的技法。墨于水的变化分为五色。画成作品，题款，盖章。就是完整的墨水画作品。\n",
    "基本的水墨画，仅有水与墨，黑与白色，但进阶的水墨画，也有工笔花鸟画，色彩缤纷。后者有时也称为彩墨画。在中国画中，以中国画特有的材料之一，墨为主要原料加以清水的多少引为浓墨、淡墨、干墨、湿墨、焦墨等，画出不同浓淡（黑、白、灰）层次。别有一番韵味称为“墨韵”。而形成水墨为主的一种绘画形式。”''')\n",
    "                with gr.Column(scale=1):\n",
    "                    img_num = gr.Dropdown(\n",
    "                        [\"Automatic (自动)\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\"],\n",
    "                        value='6', label=\"Image Number (插图数量)\", info=\"Select the number of the inserted images\",\n",
    "                        interactive=True)\n",
    "                    seed = gr.Slider(minimum=1.0, maximum=20000.0, value=8909.0, step=1.0, label='Random Seed (随机种子)')\n",
    "                    btn = gr.Button(\"Submit (提交)\", scale=1)\n",
    "\n",
    "            with gr.Accordion(\"Click to add image material (点击添加图片素材）, optional（可选）\", open=False, visible=True):\n",
    "                with gr.Row():\n",
    "                    uploads = gr.File(file_count='multiple', scale=1)\n",
    "                    upshows = gr.Gallery(columns=4, scale=2)\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    with gr.Accordion(\"Advanced Settings (高级设置)\", open=False, visible=True) as parameter_article:\n",
    "                        beam = gr.Slider(minimum=1.0, maximum=6.0, value=1.0, step=1.0, label='Beam Size (集束大小)')\n",
    "                        repetition = gr.Slider(minimum=1.0, maximum=2.0, value=1.005, step=0.001, label='Repetition_penalty (重复惩罚)')\n",
    "                        text_num = gr.Slider(minimum=100.0, maximum=4096.0, value=4096.0, step=1.0, label='Max output tokens (最多输出字数)')\n",
    "                        llmO = gr.Checkbox(value=False, label='LLM Only (纯文本写作)')\n",
    "                        random = gr.Checkbox(value=True, label='Sampling (随机采样)')\n",
    "                        withmeta = gr.Checkbox(value=False, label='With Meta (使用meta指令)')\n",
    "\n",
    "            with gr.Row():\n",
    "                btn_like = gr.Button(interactive=True, visible=False, value='👍  Like This Article (点赞这篇文章)')\n",
    "                btn_dislike = gr.Button(interactive=True, visible=False, value='👎  Dislike This Article (点踩这篇文章)')\n",
    "\n",
    "            articles, edit_bts = [], []\n",
    "            text_editers, edit_types, edit_subs, insertIMGs, edit_dones, edit_cancels = [], [], [], [], [], []\n",
    "            before_edits, inst_edits, after_edits = [], [], []\n",
    "            img_editers, cap_boxs, cap_searchs, gallerys, gallery_dels, gallery_dones = [], [], [], [], [], []\n",
    "            image_shows = []\n",
    "            with gr.Column():\n",
    "                for i in range(max_section):\n",
    "                    visible = True if i == 0 else False\n",
    "                    with gr.Row():\n",
    "                        with gr.Column(scale=3):\n",
    "                            articles.append(gr.Markdown(visible=visible, elem_classes='feedback'))\n",
    "\n",
    "                        edit_bts.append(gr.Button(interactive=True, visible=False, value='\\U0001F58C', elem_classes='sm_btn'))\n",
    "                        with gr.Column(scale=2):\n",
    "                            with gr.Accordion('Text Editing (文本编辑)', open=True, visible=False) as text_editer:\n",
    "                                gr.HTML('<p style=\"color:gray;\">Befor Editing (编辑前):</p>', elem_classes='edit')\n",
    "                                gr.HTML('<p style=\"color:gray;\">===========</p>', elem_classes='edit')\n",
    "                                before_edits.append(gr.HTML('', elem_classes='edit'))\n",
    "                                gr.HTML('<p style=\"color:gray;\">===========</p>', elem_classes='edit')\n",
    "\n",
    "                                edit_types.append(gr.Radio([\"rewrite\", \"expand\", \"abbreviate\", \"insert a paragraph before\", \"insert a paragraph after\"], label=\"Paragraph modification (段落修改)\",\n",
    "                                                     info=\"选择后点击右侧按钮，模型自动修改\", elem_classes='editsmall'))\n",
    "                                with gr.Row():\n",
    "                                    inst_edits.append(gr.Textbox(label='Instrcution for editing:', interactive=False, elem_classes='editsmall'))\n",
    "                                    edit_subs.append(gr.Button(elem_classes='smax_btn'))\n",
    "\n",
    "                                gr.HTML('<p style=\"color:gray;\">After Editing (编辑后):</p>', elem_classes='edit')\n",
    "                                after_edits.append(gr.Textbox(show_label=False, elem_classes='edit'))\n",
    "\n",
    "                                with gr.Row():\n",
    "                                    insertIMGs.append(gr.Button(value='Insert image below'))\n",
    "                                    edit_dones.append(gr.Button(value='Done'))\n",
    "                                    edit_cancels.append(gr.Button(value='Cancel'))\n",
    "\n",
    "                    with gr.Row():\n",
    "                        with gr.Column(scale=3):\n",
    "                            image_shows.append(gr.Image(visible=False, width=600, elem_classes='feedback'))\n",
    "\n",
    "                        with gr.Column(scale=2):\n",
    "                            with gr.Accordion('Images Editing (图片编辑)', open=True, visible=False) as img_editer:\n",
    "                                with gr.Row():\n",
    "                                    cap_boxs.append(gr.Textbox(label='image caption (图片标题)', interactive=True, scale=6))\n",
    "                                    cap_searchs.append(gr.Button(value=\"Search\", scale=1))\n",
    "                                with gr.Row():\n",
    "                                    gallerys.append(gr.Gallery(columns=2, height='auto'))\n",
    "\n",
    "                                with gr.Row():\n",
    "                                    gallery_dels.append(gr.Button(value=\"Delete\"))\n",
    "                                    gallery_dones.append(gr.Button(value=\"Done\"))\n",
    "\n",
    "                    text_editers.append(text_editer)\n",
    "                    img_editers.append(img_editer)\n",
    "\n",
    "            save_btn = gr.Button(\"Save article (保存文章)\")\n",
    "            save_file = gr.File(label=\"Save article (保存文章)\")\n",
    "            save_btn.click(demo_ui.save, inputs=[beam, repetition, text_num, random, seed], outputs=save_file)\n",
    "\n",
    "            uploads.upload(demo_ui.upload_images, inputs=uploads, outputs=[upshows, img_num])\n",
    "            uploads.clear(demo_ui.clear_images, inputs=[], outputs=upshows)\n",
    "            img_num.select(demo_ui.limit_imagenum, inputs=[img_num, upshows], outputs=img_num)\n",
    "\n",
    "            withmeta.change(demo_ui.change_meta, inputs=withmeta, outputs=[])\n",
    "\n",
    "            for i in range(max_section):\n",
    "                edit_bts[i].click(demo_ui.show_edit, inputs=[articles[i], gr.Number(value=i, visible=False)], outputs=[text_editers[i], before_edits[i], after_edits[i]])\n",
    "                edit_types[i].select(demo_ui.edit_types_change, inputs=[edit_types[i]], outputs=[inst_edits[i]])\n",
    "                edit_subs[i].click(demo_ui.paragraph_edit, inputs=[edit_types[i], before_edits[i], inst_edits[i], gr.Number(value=i, visible=False)], outputs=[after_edits[i], insertIMGs[i], edit_dones[i]])\n",
    "                insertIMGs[i].click(demo_ui.insert_image, inputs=[], outputs=[text_editers[i], edit_types[i], inst_edits[i], after_edits[i], img_editers[i], cap_boxs[i], gallerys[i]])\n",
    "                edit_dones[i].click(demo_ui.done_edit, inputs=[edit_types[i], inst_edits[i], after_edits[i]], outputs=[text_editers[i], edit_types[i], inst_edits[i], after_edits[i]] + articles + edit_bts + image_shows)\n",
    "                edit_cancels[i].click(demo_ui.hide_edit, inputs=[], outputs=[text_editers[i], edit_types[i], inst_edits[i], after_edits[i]])\n",
    "\n",
    "                image_shows[i].select(demo_ui.show_gallery, inputs=[gr.Number(value=i, visible=False)], outputs=[img_editers[i], cap_boxs[i], gallerys[i]])\n",
    "                cap_searchs[i].click(demo_ui.search_image, inputs=[cap_boxs[i], gr.Number(value=i, visible=False)], outputs=[gallerys[i], image_shows[i]])\n",
    "                gallerys[i].select(demo_ui.replace_image, inputs=[gr.Number(value=i, visible=False)], outputs=[image_shows[i]])\n",
    "                gallery_dels[i].click(demo_ui.delete_gallery, inputs=[gr.Number(value=i, visible=False)], outputs=[image_shows[i], img_editers[i], cap_boxs[i], gallerys[i]])\n",
    "                gallery_dones[i].click(demo_ui.hide_gallery, inputs=[], outputs=[img_editers[i], cap_boxs[i], gallerys[i]])\n",
    "\n",
    "            btn_like.click(demo_ui.like, inputs=[], outputs=[btn_like, btn_dislike])\n",
    "            btn_dislike.click(demo_ui.dislike, inputs=[], outputs=[btn_like, btn_dislike])\n",
    "\n",
    "            btn.click(demo_ui.reset_components, inputs=[],\n",
    "                      outputs=articles + edit_bts + image_shows + text_editers + img_editers).then(\n",
    "                    demo_ui.generate_article,\n",
    "                    inputs=[instruction, upshows, beam, repetition, text_num, random, seed],\n",
    "                    outputs=articles + edit_bts + image_shows).then(\n",
    "                    demo_ui.insert_images, inputs=[upshows, llmO, img_num, seed], outputs=articles + edit_bts + image_shows).then(\n",
    "                    demo_ui.enable_like, inputs=[], outputs=[btn_like, btn_dislike])\n",
    "\n",
    "\n",
    "    lang_btn.click(change_language, inputs=lang_btn, outputs=[lang_btn] + edit_types + inst_edits + insertIMGs + edit_dones + edit_cancels + cap_searchs + gallery_dels + gallery_dones)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if args.private:\n",
    "        demo.queue().launch(share=False, server_name=\"127.0.0.1\", server_port=args.port, max_threads=1)\n",
    "    else:\n",
    "        demo.queue().launch(share=True, server_name=\"0.0.0.0\", server_port=args.port, max_threads=1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1ed8f885f5cef34"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 启动命名\n",
    "\n",
    "python /root/demo/InternLM-XComposer/examples/gradio_demo_composition.py  \\   # 脚本路径\n",
    "--code_path /root/models/internlm-xcomposer2-7b \\\n",
    "--private \\\n",
    "--num_gpus 1 \\\n",
    "--port 6006"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c21fbe285b9a8ff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 图片理解实战"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c43f1f0adf6888e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 下载模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5dc33dbb3c8dd24"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "from modelscope.hub.snapshot_download import snapshot_download\n",
    "\n",
    "# 创建保存模型目录\n",
    "os.system(\"mkdir /root/models\")\n",
    "\n",
    "# save_dir是模型保存到本地的目录\n",
    "save_dir=\"/root/models\"\n",
    "\n",
    "snapshot_download(\"Shanghai_AI_Laboratory/internlm-xcomposer2-vl-7b\", cache_dir=save_dir)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b39c527ac1a0ac9c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 构建gradio交互界面"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea3f5f481728cdac"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import argparse\n",
    "import gradio as gr\n",
    "os.environ[\"GRADIO_TEMP_DIR\"] = os.path.join(os.getcwd(), 'tmp')\n",
    "import time\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from PIL import Image, ImageFile\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from demo_asset.assets.css_html_js import custom_css\n",
    "from demo_asset.gradio_patch import Chatbot as grChatbot\n",
    "from demo_asset.serve_utils import Stream, Iteratorize\n",
    "from demo_asset.conversation import CONV_VISION_INTERN2\n",
    "from examples.utils import auto_configure_device_map, get_stopping_criteria, set_random_seed\n",
    "\n",
    "\n",
    "meta_instruction = \"\"\"You are an AI assistant whose name is InternLM-XComposer (浦语·灵笔).\n",
    "- InternLM-XComposer (浦语·灵笔) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be helpful, honest, and harmless.\n",
    "- InternLM-XComposer (浦语·灵笔) can understand and communicate fluently in the language chosen by the user such as English and 中文.\n",
    "\"\"\"\n",
    "chat_meta = \"\"\"You are an AI assistant whose name is InternLM-XComposer (浦语·灵笔).\n",
    "- InternLM-XComposer (浦语·灵笔) is a multi-modality conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be helpful, honest, and harmless.\n",
    "- InternLM-XComposer (浦语·灵笔) can understand and communicate fluently in the language chosen by the user such as English and 中文.\n",
    "- InternLM-XComposer (浦语·灵笔) is capable of comprehending and articulating responses effectively based on the provided image.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "chat_stream_output = True\n",
    "\n",
    "class Demo_UI:\n",
    "    def __init__(self, code_path, num_gpus=1):\n",
    "        self.code_path = code_path\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(code_path, trust_remote_code=True)\n",
    "        self.chat_model = AutoModelForCausalLM.from_pretrained(code_path, device_map='cuda', trust_remote_code=True).half().eval()\n",
    "        self.chat_model.tokenizer = tokenizer\n",
    "\n",
    "        stop_words_ids = [92542]\n",
    "        self.stopping_criteria = get_stopping_criteria(stop_words_ids)\n",
    "        set_random_seed(1234)\n",
    "        self.folder = None\n",
    "\n",
    "    def get_context_emb(self, state, img_list):\n",
    "        prompt = state.get_prompt()\n",
    "        print(prompt)\n",
    "        prompt_segs = prompt.split('<Img><ImageHere></Img>')\n",
    "\n",
    "        assert len(prompt_segs) == len(\n",
    "            img_list\n",
    "        ) + 1, \"Unmatched numbers of image placeholders and images.\"\n",
    "        seg_tokens = [\n",
    "            self.chat_model.tokenizer(seg, return_tensors=\"pt\",  add_special_tokens=i == 0).input_ids.to(0)\n",
    "            for i, seg in enumerate(prompt_segs)\n",
    "        ]\n",
    "        seg_embs = [self.chat_model.model.tok_embeddings(seg_t) for seg_t in seg_tokens]\n",
    "        txt_mask = [torch.zeros(seg_e.shape[:2]) for seg_e in seg_embs]\n",
    "        mixed_embs = [emb for pair in zip(seg_embs[:-1], img_list) for emb in pair] + [seg_embs[-1]]\n",
    "        maxed_masks = [emb for pair in zip(txt_mask[:-1], [torch.ones(img.shape[:2]) for img in img_list]) for emb in pair] + [txt_mask[-1]]\n",
    "        mixed_embs = torch.cat(mixed_embs, dim=1)\n",
    "        maxed_masks = torch.cat(maxed_masks, dim=1).bool()\n",
    "        return mixed_embs, maxed_masks\n",
    "\n",
    "    def generate_with_chat_callback(self, callback=None, **kwargs):\n",
    "        kwargs.setdefault(\"stopping_criteria\",\n",
    "                          transformers.StoppingCriteriaList())\n",
    "        kwargs[\"stopping_criteria\"].append(Stream(callback_func=callback))\n",
    "        with torch.no_grad():\n",
    "            self.chat_model.generate(**kwargs)\n",
    "\n",
    "    def generate_with_chat_streaming(self, **kwargs):\n",
    "        return Iteratorize(self.generate_with_chat_callback, kwargs, callback=None)\n",
    "\n",
    "    def chat_ask(self, state, img_list, text, image):\n",
    "        print(1111)\n",
    "        state.skip_next = False\n",
    "        if len(text) <= 0 and image is None:\n",
    "            state.skip_next = True\n",
    "            return (state, img_list, state.to_gradio_chatbot(), \"\",\n",
    "                    None) + (gr.Button(), ) * 2\n",
    "\n",
    "        if image is not None:\n",
    "            imgs = []\n",
    "            imgs_pil = []\n",
    "            for j in range(len(image)):\n",
    "                img_pil = Image.open(image[j]).convert('RGB')\n",
    "                imgs_pil.append(img_pil)\n",
    "                img = self.chat_model.vis_processor(img_pil)\n",
    "                imgs.append(img)\n",
    "            imgs = torch.stack(imgs, dim=0)\n",
    "            print(imgs.shape)\n",
    "            with torch.no_grad():\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    image_emb = self.chat_model.encode_img(imgs)\n",
    "\n",
    "            image_emb = torch.cat([t.unsqueeze(0) for t in image_emb], dim=1)\n",
    "            print(image_emb.shape)\n",
    "            img_list.append(image_emb)\n",
    "\n",
    "            state.append_message(state.roles[0],\n",
    "                                 [\"<Img><ImageHere></Img>\", imgs_pil])\n",
    "\n",
    "        if len(state.messages) > 0 and state.messages[-1][0] == state.roles[\n",
    "                0] and isinstance(state.messages[-1][1], list):\n",
    "            #state.messages[-1][1] = ' '.join([state.messages[-1][1], text])\n",
    "            state.messages[-1][1][0] = ''.join(\n",
    "                [state.messages[-1][1][0], text])\n",
    "        else:\n",
    "            state.append_message(state.roles[0], text)\n",
    "\n",
    "        print(state.messages)\n",
    "\n",
    "        state.append_message(state.roles[1], None)\n",
    "\n",
    "        return (state, img_list, state.to_gradio_chatbot(), \"\",\n",
    "                None) + (gr.Button(interactive=False), ) * 4\n",
    "\n",
    "    def chat_answer(self, state, img_list, max_output_tokens,\n",
    "                    repetition_penalty, num_beams, do_sample):\n",
    "        state.system = f\"[UNUSED_TOKEN_146]system\\n{chat_meta}[UNUSED_TOKEN_145]\\n\"\n",
    "        if state.skip_next:\n",
    "            return (state, state.to_gradio_chatbot()) + (gr.Button(), ) * 2\n",
    "\n",
    "        embs, im_mask = self.get_context_emb(state, img_list)\n",
    "        if chat_stream_output:\n",
    "            generate_params = dict(\n",
    "                inputs_embeds=embs,\n",
    "                num_beams=num_beams,\n",
    "                do_sample=do_sample,\n",
    "                stopping_criteria=self.stopping_criteria,\n",
    "                repetition_penalty=float(repetition_penalty),\n",
    "                max_length=max_output_tokens,\n",
    "                bos_token_id=self.chat_model.tokenizer.bos_token_id,\n",
    "                eos_token_id=self.chat_model.tokenizer.eos_token_id,\n",
    "                pad_token_id=self.chat_model.tokenizer.pad_token_id,\n",
    "                im_mask=im_mask,\n",
    "            )\n",
    "            state.messages[-1][-1] = \"▌\"\n",
    "            with self.generate_with_chat_streaming(**generate_params) as generator:\n",
    "                for output in generator:\n",
    "                    decoded_output = self.chat_model.tokenizer.decode(\n",
    "                        output[1:])\n",
    "                    if output[-1] in [\n",
    "                            self.chat_model.tokenizer.eos_token_id, 92542\n",
    "                    ]:\n",
    "                        break\n",
    "                    state.messages[-1][-1] = decoded_output + \"▌\"\n",
    "                    yield (state,\n",
    "                           state.to_gradio_chatbot()) + (gr.Button(interactive=False), ) * 4\n",
    "                    time.sleep(0.03)\n",
    "            state.messages[-1][-1] = [state.messages[-1][-1][:-1], '']\n",
    "            if self.folder and os.path.exists(self.folder):\n",
    "                with open(os.path.join(self.folder, 'chat.txt'), 'a+') as fd:\n",
    "                    if isinstance(state.messages[-2][1], str):\n",
    "                        fd.write(state.messages[-2][0] + state.messages[-2][1])\n",
    "                    else:\n",
    "                        fd.write(state.messages[-2][0] + state.messages[-2][1][0])\n",
    "                    fd.write(state.messages[-1][0] + ''.join(state.messages[-1][1]))\n",
    "\n",
    "            yield (state, state.to_gradio_chatbot()) + (gr.Button(interactive=True), ) * 4\n",
    "            return\n",
    "        else:\n",
    "            outputs = self.chat_model.generate(\n",
    "                inputs_embeds=embs,\n",
    "                max_new_tokens=max_output_tokens,\n",
    "                stopping_criteria=self.stopping_criteria,\n",
    "                num_beams=num_beams,\n",
    "                #temperature=float(temperature),\n",
    "                do_sample=do_sample,\n",
    "                repetition_penalty=float(repetition_penalty),\n",
    "                bos_token_id=self.chat_model.tokenizer.bos_token_id,\n",
    "                eos_token_id=self.chat_model.tokenizer.eos_token_id,\n",
    "                pad_token_id=self.chat_model.tokenizer.pad_token_id,\n",
    "                im_mask=im_mask,\n",
    "            )\n",
    "\n",
    "            output_token = outputs[0]\n",
    "            if output_token[0] == 0:\n",
    "                output_token = output_token[1:]\n",
    "            output_text = self.chat_model.tokenizer.decode(output_token, add_special_tokens=False)\n",
    "            print(output_text)\n",
    "            output_text = output_text.split('<TOKENS_UNUSED_1>')[\n",
    "                0]  # remove the stop sign '###'\n",
    "            output_text = output_text.split('Assistant:')[-1].strip()\n",
    "            output_text = output_text.replace(\"<s>\", \"\")\n",
    "            state.messages[-1][1] = output_text\n",
    "\n",
    "            return (state, state.to_gradio_chatbot()) + (gr.Button(interactive=True), ) * 4\n",
    "\n",
    "    def clear_answer(self, state):\n",
    "        state.messages[-1][-1] = None\n",
    "        return (state, state.to_gradio_chatbot())\n",
    "\n",
    "    def chat_clear_history(self):\n",
    "        state = CONV_VISION_INTERN2.copy()\n",
    "        return (state, [], state.to_gradio_chatbot(), \"\", None) + (gr.Button(interactive=False), ) * 4\n",
    "\n",
    "    def uploadimgs(self, images):\n",
    "        timestamp = datetime.now()\n",
    "        self.folder = os.path.join('databases', timestamp.strftime(\"%Y%m%d\"), 'chat', str(timestamp).replace(' ', '-'))\n",
    "        os.makedirs(self.folder, exist_ok=True)\n",
    "        for image_path in images:\n",
    "            shutil.copy(image_path, self.folder)\n",
    "\n",
    "    def like(self, state):\n",
    "        if self.folder and os.path.exists(self.folder):\n",
    "            with open(os.path.join(self.folder, 'chat.txt'), 'r') as fd:\n",
    "                content = fd.read()\n",
    "\n",
    "            if content[-1] == '👎':\n",
    "                content = content[:-1]\n",
    "            if content[-1] != '👍':\n",
    "                content = content + '👍'\n",
    "\n",
    "            state.messages[-1][-1][1] = '👍'\n",
    "\n",
    "            with open(os.path.join(self.folder, 'chat.txt'), 'w') as fd:\n",
    "                fd.write(content)\n",
    "\n",
    "        return state, state.to_gradio_chatbot()\n",
    "\n",
    "    def dislike(self, state):\n",
    "        if self.folder and os.path.exists(self.folder):\n",
    "            with open(os.path.join(self.folder, 'chat.txt'), 'r') as fd:\n",
    "                content = fd.read()\n",
    "\n",
    "            if content[-1] == '👍':\n",
    "                content = content[:-1]\n",
    "            if content[-1] != '👎':\n",
    "                content = content + '👎'\n",
    "\n",
    "            state.messages[-1][-1][1] = '👎'\n",
    "\n",
    "            with open(os.path.join(self.folder, 'chat.txt'), 'w') as fd:\n",
    "                fd.write(content)\n",
    "\n",
    "        return state, state.to_gradio_chatbot()\n",
    "\n",
    "\n",
    "def load_demo():\n",
    "    state = CONV_VISION_INTERN2.copy()\n",
    "\n",
    "    return (state, [], gr.Chatbot(visible=True),\n",
    "            gr.Textbox(visible=True), gr.Button(visible=True),\n",
    "            gr.Row(visible=True), gr.Accordion(visible=True))\n",
    "\n",
    "\n",
    "def change_language(lang):\n",
    "    if lang == '中文':\n",
    "        lang_btn = gr.Button(value='English')\n",
    "        chat_textbox = gr.update(placeholder='输入聊天内容并回车')\n",
    "        submit_btn = gr.update(value='提交')\n",
    "        regenerate_btn = gr.update(value='🔄  重新生成')\n",
    "        clear_btn = gr.update(value='🗑️  清空聊天框')\n",
    "    elif lang == 'English':\n",
    "        lang_btn = gr.Button(value='中文')\n",
    "        chat_textbox = gr.update(placeholder='Enter text and press ENTER')\n",
    "        submit_btn = gr.update(value='Submit')\n",
    "        regenerate_btn = gr.update(value='🔄  Regenerate')\n",
    "        clear_btn = gr.update(value='🗑️  Clear history')\n",
    "\n",
    "    return [lang_btn, chat_textbox, submit_btn, regenerate_btn, clear_btn]\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--code_path\", default='internlm/internlm-xcomposer2-vl-7b')\n",
    "parser.add_argument(\"--private\", default=False, action='store_true')\n",
    "parser.add_argument(\"--num_gpus\", default=1, type=int)\n",
    "parser.add_argument(\"--port\", default=11111, type=int)\n",
    "args = parser.parse_args()\n",
    "demo_ui = Demo_UI(args.code_path, args.num_gpus)\n",
    "\n",
    "\n",
    "with gr.Blocks(css=custom_css, title='浦语·灵笔 (InternLM-XComposer)') as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=20):\n",
    "            # gr.HTML(\"\"\"<h1 align=\"center\" id=\"space-title\" style=\"font-size:35px;\">🤗 浦语·灵笔 (InternLM-XComposer)</h1>\"\"\")\n",
    "            gr.HTML(\n",
    "                \"\"\"<h1 align=\"center\"><img src=\"https://raw.githubusercontent.com/InternLM/InternLM-XComposer/InternLM-XComposer2/assets/logo_en.png\", alt=\"InternLM-XComposer\" border=\"0\" style=\"margin: 0 auto; height: 120px;\" /></a> </h1>\"\"\"\n",
    "            )\n",
    "        with gr.Column(scale=1, min_width=100):\n",
    "            lang_btn = gr.Button(\"中文\")\n",
    "\n",
    "    with gr.Tabs(elem_classes=\"tab-buttons\") as tabs:\n",
    "        with gr.TabItem(\"💬 Multimodal Chat (多模态对话)\", elem_id=\"chat\", id=0):\n",
    "            chat_state = gr.State()\n",
    "            img_list = gr.State()\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=3):\n",
    "                    imagebox = gr.File(file_count='multiple')\n",
    "\n",
    "                    with gr.Accordion(\"Parameters (参数)\", open=True,\n",
    "                                      visible=False) as parameter_row:\n",
    "                        chat_max_output_tokens = gr.Slider(\n",
    "                            minimum=0,\n",
    "                            maximum=1024,\n",
    "                            value=512,\n",
    "                            step=64,\n",
    "                            interactive=True,\n",
    "                            label=\"Max output tokens (最多输出字数)\",\n",
    "                        )\n",
    "                        chat_num_beams = gr.Slider(\n",
    "                            minimum=1,\n",
    "                            maximum=5,\n",
    "                            value=1,\n",
    "                            step=1,\n",
    "                            interactive=True,\n",
    "                            label=\"Beam Size (集束大小)\",\n",
    "                        )\n",
    "                        chat_repetition_penalty = gr.Slider(\n",
    "                            minimum=1,\n",
    "                            maximum=2,\n",
    "                            value=1.005,\n",
    "                            step=0.001,\n",
    "                            interactive=True,\n",
    "                            label=\"Repetition_penalty (重复惩罚)\",\n",
    "                        )\n",
    "                        # chat_temperature = gr.Slider(minimum=0, maximum=1, value=1, step=0.1, interactive=True,\n",
    "                        #                         label=\"Temperature\", )\n",
    "                        chat_do_sample = gr.Checkbox(interactive=True,\n",
    "                                                     value=True,\n",
    "                                                     label=\"Do_sample (采样)\")\n",
    "\n",
    "                with gr.Column(scale=6):\n",
    "                    chatbot = grChatbot(elem_id=\"chatbot\",\n",
    "                                        visible=False,\n",
    "                                        height=750)\n",
    "                    with gr.Row():\n",
    "                        with gr.Column(scale=8):\n",
    "                            chat_textbox = gr.Textbox(\n",
    "                                show_label=False,\n",
    "                                placeholder=\"Enter text and press ENTER (输入聊天内容并回车)\",\n",
    "                                visible=False)\n",
    "                        with gr.Column(scale=1, min_width=60):\n",
    "                            submit_btn = gr.Button(value=\"Submit\",\n",
    "                                                   visible=False)\n",
    "                    with gr.Row(visible=True) as button_row:\n",
    "                        regenerate_btn = gr.Button(value=\"🔄  Regenerate\",\n",
    "                                                   interactive=False)\n",
    "                        clear_btn = gr.Button(value=\"🗑️  Clear history\",\n",
    "                                              interactive=False)\n",
    "                        btn_like = gr.Button(interactive=False, value='👍  Like (点赞)')\n",
    "                        btn_dislike = gr.Button(interactive=False, value='👎  Dislike (点踩)')\n",
    "\n",
    "            btn_list = [regenerate_btn, clear_btn, btn_like, btn_dislike]\n",
    "            parameter_list = [\n",
    "                chat_max_output_tokens, chat_repetition_penalty,\n",
    "                chat_num_beams, chat_do_sample\n",
    "            ]\n",
    "\n",
    "            imagebox.upload(demo_ui.uploadimgs, imagebox, [])\n",
    "            btn_like.click(demo_ui.like, [chat_state], [chat_state, chatbot])\n",
    "            btn_dislike.click(demo_ui.dislike, [chat_state], [chat_state, chatbot])\n",
    "\n",
    "            chat_textbox.submit(\n",
    "                demo_ui.chat_ask,\n",
    "                [chat_state, img_list, chat_textbox, imagebox],\n",
    "                [chat_state, img_list, chatbot, chat_textbox, imagebox] +\n",
    "                btn_list).then(demo_ui.chat_answer,\n",
    "                               [chat_state, img_list] + parameter_list,\n",
    "                               [chat_state, chatbot] + btn_list)\n",
    "            submit_btn.click(\n",
    "                demo_ui.chat_ask,\n",
    "                [chat_state, img_list, chat_textbox, imagebox],\n",
    "                [chat_state, img_list, chatbot, chat_textbox, imagebox] +\n",
    "                btn_list).then(demo_ui.chat_answer,\n",
    "                               [chat_state, img_list] + parameter_list,\n",
    "                               [chat_state, chatbot] + btn_list)\n",
    "\n",
    "            regenerate_btn.click(demo_ui.clear_answer, chat_state,\n",
    "                                 [chat_state, chatbot]).then(\n",
    "                                demo_ui.chat_answer,\n",
    "                                [chat_state, img_list] + parameter_list,\n",
    "                                [chat_state, chatbot] + btn_list)\n",
    "            clear_btn.click(\n",
    "                demo_ui.chat_clear_history, None,\n",
    "                [chat_state, img_list, chatbot, chat_textbox, imagebox] +\n",
    "                btn_list)\n",
    "\n",
    "            demo.load(load_demo, None, [\n",
    "                chat_state, img_list, chatbot, chat_textbox, submit_btn,\n",
    "                parameter_row\n",
    "            ])\n",
    "\n",
    "    lang_btn.click(change_language, inputs=lang_btn, outputs=[lang_btn, chat_textbox, submit_btn, regenerate_btn, clear_btn])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if args.private:\n",
    "        demo.queue().launch(share=False, server_name=\"127.0.0.1\", server_port=args.port, max_threads=1)\n",
    "    else:\n",
    "        demo.queue().launch(share=True, server_name=\"0.0.0.0\", server_port=args.port, max_threads=1)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8e79b2d5d309bf5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 启动命名\n",
    "\n",
    "python /root/demo/InternLM-XComposer/examples/gradio_demo_composition.py  \\  # 脚本路径\n",
    "--code_path /root/models/internlm-xcomposer2-7b \\\n",
    "--private \\\n",
    "--num_gpus 1 \\\n",
    "--port 6006"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cb6e27942bbf191"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b34c31c7c269b4d7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
